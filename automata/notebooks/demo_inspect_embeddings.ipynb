{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ed49ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from automata.core.utils import config_fpath\n",
    "from automata.config.config_types import ConfigCategory\n",
    "from automata.core.database.vector import JSONVectorDatabase\n",
    "from automata.core.symbol.graph import SymbolGraph\n",
    "from automata.core.symbol.search.rank import SymbolRankConfig, SymbolRank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1e3f338",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 699/699 [00:00<00:00, 5614.49it/s]\n"
     ]
    }
   ],
   "source": [
    "scip_path = os.path.join(\n",
    "    config_fpath(), ConfigCategory.SYMBOL.value, \"index.scip\"\n",
    ")\n",
    "symbol_graph = SymbolGraph(scip_path)\n",
    "\n",
    "symbol_rank_config = SymbolRankConfig()\n",
    "symbol_graph_subgraph = symbol_graph.get_rankable_symbol_subgraph()\n",
    "symbol_rank = SymbolRank(symbol_graph_subgraph.graph, SymbolRankConfig())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f17770ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "ranks = symbol_rank.get_ranks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "98d33f48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing out Code Embeddings for top ten ranked symbols\n",
      "\n",
      "--->Symbol DotPath<---\n",
      "automata.core.symbol.symbol_types.Symbol\n",
      "\n",
      "Integer Rank=0, Rank Score=0.006\n",
      "\n",
      "--->Documentation Code<---\n",
      "\n",
      "@dataclass\n",
      "class Symbol:\n",
      "    \"\"\"\n",
      "    Symbol is similar to a URI, it identifies a class, method, or a local variable. SymbolInformation contains rich metadata about symbols such as the docstring.\n",
      "\n",
      "    Symbol has a standardized string representation, which can be used interchangeably with Symbol. The syntax for Symbol is the following:\n",
      "\n",
      "    # (<x>)+ stands for one or more repetitions of <x>\n",
      "    <symbol>               ::= <scheme> ' ' <package> ' ' (<descriptor>)+ | 'local ' <local-id>\n",
      "    <package>              ::= <manager> ' ' <package-name> ' ' <version>\n",
      "    <scheme>               ::= any UTF-8, escape spaces with double space.\n",
      "    <manager>              ::= same as above, use the placeholder '.' to indicate an empty value\n",
      "    <package-name>         ::= same as above\n",
      "    <version>              ::= same as above\n",
      "    <descriptor>           ::= <namespace> | <type> | <term> | <method> | <type-parameter> | <parameter> | <meta> | <macro>\n",
      "    <namespace>            ::= <name> '/'\n",
      "    <type>                 ::= <name> '#'\n",
      "    <term>                 ::= <name> '.'\n",
      "    <meta>                 ::= <name> ':'\n",
      "    <macro>                ::= <name> '!'\n",
      "    <method>               ::= <name> '(' <method-disambiguator> ').'\n",
      "    <type-parameter>       ::= '[' <name> ']'\n",
      "    <parameter>            ::= '(' <name> ')'\n",
      "    <name>                 ::= <identifier>\n",
      "    <method-disambiguator> ::= <simple-identifier>\n",
      "    <identifier>           ::= <simple-identifier> | <escaped-identifier>\n",
      "    <simple-identifier>    ::= (<identifier-character>)+\n",
      "    <identifier-character> ::= '_' | '+' | '-' | '$' | ASCII letter or digit\n",
      "    <escaped-identifier>   ::= '`' (<escaped-character>)+ '`'\n",
      "    <escaped-characters>   ::= any UTF-8 character, escape backticks with double backtick.\n",
      "\n",
      "    Examples -\n",
      "    from automata.core.symbol.search.symbol_parser import parse_symbol\n",
      "\n",
      "    symbol_class = parse_symbol(\n",
      "        \"scip-python python automata 75482692a6fe30c72db516201a6f47d9fb4af065 `automata.core.agent.agent_enums`/ActionIndicator#\"\n",
      "    )\n",
      "\n",
      "    symbol_method = parse_symbol(\n",
      "        \"scip-python python automata 75482692a6fe30c72db516201a6f47d9fb4af065 `automata.core.base.tool`/ToolNotFoundError#__init__().\"\n",
      "    )\n",
      "    \"\"\"\n",
      "\n",
      "    uri: str\n",
      "    scheme: str\n",
      "    package: SymbolPackage\n",
      "    descriptors: Tuple[SymbolDescriptor, ...]\n",
      "\n",
      "    def __repr__(self) -> str:\n",
      "        \"\"\"Converts back into URI string\"\"\"\n",
      "        return f\"Symbol({self.uri}, {self.scheme}, {self.package}, {self.descriptors})\"\n",
      "\n",
      "    def __hash__(self) -> int:\n",
      "        \"\"\"Hashes the URI string\"\"\"\n",
      "        return hash(self.uri)\n",
      "\n",
      "    def __eq__(self, other) -> bool:\n",
      "        \"\"\"Compares the URI string\"\"\"\n",
      "        if isinstance(other, Symbol):\n",
      "            return self.uri == other.uri\n",
      "        elif isinstance(other, str):\n",
      "            return self.uri == other\n",
      "        return False\n",
      "\n",
      "    def symbol_kind_by_suffix(self) -> SymbolDescriptor.PyKind:\n",
      "        \"\"\"Converts the suffix of the URI into a PyKind\"\"\"\n",
      "        return SymbolDescriptor.convert_scip_to_python_suffix(self.symbol_raw_kind_by_suffix())\n",
      "\n",
      "    def symbol_raw_kind_by_suffix(self) -> DescriptorProto:\n",
      "        \"\"\"Converts the suffix of the URI into a DescriptorProto\"\"\"\n",
      "        if self.uri.startswith(\"local\"):\n",
      "            return SymbolDescriptor.ScipSuffix.Local\n",
      "        if self.uri.endswith(\"/\"):\n",
      "            return SymbolDescriptor.ScipSuffix.Namespace\n",
      "        elif self.uri.endswith(\"#\"):\n",
      "            return SymbolDescriptor.ScipSuffix.Type\n",
      "        elif self.uri.endswith(\").\"):\n",
      "            return SymbolDescriptor.ScipSuffix.Method\n",
      "        elif self.uri.endswith(\".\"):\n",
      "            return SymbolDescriptor.ScipSuffix.Term\n",
      "        elif self.uri.endswith(\":\"):\n",
      "            return SymbolDescriptor.ScipSuffix.Meta\n",
      "        elif self.uri.endswith(\")\"):\n",
      "            return SymbolDescriptor.ScipSuffix.Parameter\n",
      "        elif self.uri.endswith(\"]\"):\n",
      "            return SymbolDescriptor.ScipSuffix.TypeParameter\n",
      "        else:\n",
      "            raise ValueError(f\"Invalid descriptor suffix: {self.uri}\")\n",
      "\n",
      "    def parent(self) -> \"Symbol\":\n",
      "        \"\"\"Returns the parent symbol of the current symbol\"\"\"\n",
      "        parent_descriptors = list(self.descriptors)[:-1]\n",
      "        return Symbol(self.uri, self.scheme, self.package, tuple(parent_descriptors))\n",
      "\n",
      "    @property\n",
      "    def dotpath(self) -> str:\n",
      "        \"\"\"Returns the dotpath of the symbol\"\"\"\n",
      "        return \".\".join([ele.name for ele in self.descriptors])\n",
      "\n",
      "    @property\n",
      "    def module_name(self) -> str:\n",
      "        \"\"\"Returns the module name of the symbol\"\"\"\n",
      "        return self.descriptors[0].name\n",
      "\n",
      "    @staticmethod\n",
      "    def is_local(symbol: \"Symbol\") -> bool:\n",
      "        \"\"\"Returns True if the symbol is local\"\"\"\n",
      "        return symbol.descriptors[0].suffix == SymbolDescriptor.ScipSuffix.Local\n",
      "\n",
      "    @staticmethod\n",
      "    def is_meta(symbol: \"Symbol\") -> bool:\n",
      "        \"\"\"Returns True if the symbol is meta\"\"\"\n",
      "        return symbol.descriptors[0].suffix == SymbolDescriptor.ScipSuffix.Meta\n",
      "\n",
      "    @staticmethod\n",
      "    def is_parameter(symbol: \"Symbol\") -> bool:\n",
      "        \"\"\"Returns True if the symbol is parameter\"\"\"\n",
      "        return symbol.descriptors[0].suffix == SymbolDescriptor.ScipSuffix.Parameter\n",
      "\n",
      "    @staticmethod\n",
      "    def is_protobuf(symbol: \"Symbol\") -> bool:\n",
      "        \"\"\"Returns True if the symbol is a protobuf symbol\"\"\"\n",
      "        return symbol.module_name.endswith(\"pb2\")\n",
      "\n",
      "    @classmethod\n",
      "    def from_string(cls, symbol_str: str) -> \"Symbol\":\n",
      "        \"\"\"\n",
      "        Creates a Symbol instance from a string representation\n",
      "\n",
      "        :param symbol_str: The string representation of the Symbol\n",
      "        :return: A Symbol instance\n",
      "        \"\"\"\n",
      "        # Assuming symbol_str is in the format: \"Symbol({uri}, {scheme}, Package({manager} {name} {version}), [{Descriptor},...])\"\n",
      "        # Parse the symbol_str to extract the uri, scheme, package_str, and descriptors_str\n",
      "        match = re.search(r\"Symbol\\((.*?), (.*?), Package\\((.*?)\\), \\((.*?)\\)\\)\", symbol_str)\n",
      "        if not match:\n",
      "            raise ValueError(f\"Invalid symbol_str: {symbol_str}\")\n",
      "        uri, _, __, ___ = match.groups()\n",
      "        # In current implementation, only the uri is used in re-construcing the symbol\n",
      "        from automata.core.symbol.parser import parse_symbol\n",
      "\n",
      "        return parse_symbol(uri)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "--->Vector<---\n",
      "\n",
      "[-0.00352377  0.03093975 -0.00181361 ... -0.00026862 -0.01297387\n",
      " -0.03307537]\n",
      "\n",
      "--->Symbol DotPath<---\n",
      "automata.core.agent.agent.AutomataAgent\n",
      "\n",
      "Integer Rank=1, Rank Score=0.004\n",
      "\n",
      "--->Documentation Code<---\n",
      "\n",
      "class AutomataAgent(Agent):\n",
      "    \"\"\"\n",
      "    AutomataAgent is an autonomous agent designed to execute instructions and report\n",
      "        the results back to the main system. It communicates with the OpenAI API to generate\n",
      "        responses based on given instructions and manages interactions with various tools.\n",
      "    \"\"\"\n",
      "\n",
      "    CONTINUE_MESSAGE: Final = \"Continue, and return a result JSON when finished.\"\n",
      "    NUM_DEFAULT_MESSAGES: Final = 3  # Prompt + Assistant Initialization + User Task\n",
      "    INITIALIZER_DUMMY: Final = \"automata_initializer\"\n",
      "    ERROR_DUMMY_TOOL: Final = \"error_reporter\"\n",
      "\n",
      "    def __init__(self, instructions: str, config: AutomataAgentConfig) -> None:\n",
      "        \"\"\"\n",
      "        Initializes an AutomataAgent.\n",
      "\n",
      "        Args:\n",
      "            instructions (str): The instructions to be executed by the agent.\n",
      "            config (AutomataAgentConfig): The configuration for the agent. Defaults to None.\n",
      "        \"\"\"\n",
      "        self.config = config\n",
      "        self.completed = False\n",
      "        self.instructions = instructions\n",
      "        self.messages: List[OpenAIChatMessage] = []\n",
      "        self.coordinator: Optional[\"AutomataCoordinator\"] = None\n",
      "\n",
      "    def set_coordinator(self, coordinator: \"AutomataCoordinator\") -> None:\n",
      "        \"\"\"\n",
      "        Set the coordinator for the AutomataAgent, necessary for the main agent.\n",
      "\n",
      "        Args:\n",
      "            coordinator (AutomataCoordinator): An instance of an AutomataCoordinator.\n",
      "        \"\"\"\n",
      "\n",
      "        self.coordinator = coordinator\n",
      "\n",
      "    def iter_step(self) -> Optional[Tuple[OpenAIChatMessage, OpenAIChatMessage]]:\n",
      "        \"\"\"\n",
      "        Executes a single iteration of the task and returns the latest assistant and user messages.\n",
      "\n",
      "        Raises:\n",
      "            ValueError: If the agent has already completed its task.\n",
      "\n",
      "        Returns:\n",
      "            Optional[Tuple[OpenAIChatMessage, OpenAIChatMessage]]: Latest assistant and user messages, or None if the task is completed.\n",
      "        \"\"\"\n",
      "        if self.completed:\n",
      "            raise ValueError(\"Cannot run an agent that has already completed.\")\n",
      "\n",
      "        response_text = self._get_openai_response()\n",
      "\n",
      "        observations = self._generate_observations(response_text)\n",
      "\n",
      "        completion_message = retrieve_completion_message(observations)\n",
      "        if completion_message is not None:\n",
      "            self.completed = True\n",
      "            self._save_message(\"assistant\", self._parse_completion_message(completion_message))\n",
      "            return None\n",
      "\n",
      "        assistant_message = self._save_message(\"assistant\", response_text)\n",
      "        user_message = self._save_message(\n",
      "            \"user\",\n",
      "            generate_user_observation_message(observations)\n",
      "            if len(observations) > 0\n",
      "            else AutomataAgent.CONTINUE_MESSAGE,\n",
      "        )\n",
      "\n",
      "        return (assistant_message, user_message)\n",
      "\n",
      "    def run(self) -> str:\n",
      "        \"\"\"\n",
      "        Runs the agent and iterates through the tasks until a result is produced\n",
      "          or the max iterations are exceeded.\n",
      "\n",
      "        Returns:\n",
      "            str: The final result or an error message if the result wasn't found in time.\n",
      "        \"\"\"\n",
      "        latest_responses = self.iter_step()\n",
      "        while latest_responses is not None:\n",
      "            # Each iteration adds two messages, one from the assistant and one from the user\n",
      "            # If we have equal to or more than 2 * max_iters messages (less the default messages),\n",
      "            # then we have exceeded the max_iters\n",
      "            if (\n",
      "                len(self.messages) - AutomataAgent.NUM_DEFAULT_MESSAGES\n",
      "                >= self.config.max_iters * 2\n",
      "            ):\n",
      "                debug_summary = self._get_debug_summary()\n",
      "                return f\"Result was not found before iterations exceeded configured max limit: {self.config.max_iters}. Debug summary: {debug_summary}\"\n",
      "            latest_responses = self.iter_step()\n",
      "        return self.messages[-1].content\n",
      "\n",
      "    def run_further_with_new_instructions(self, further_instructions: str) -> str:\n",
      "        \"\"\"\n",
      "        Runs the agent further with new instructions.\n",
      "        This is intended to be called after the agent has completed its task.\n",
      "        The intended use case is to allow users to submit follow-up instructions\n",
      "\n",
      "        Args:\n",
      "            further_instructions (str): The new instructions to be executed by the agent.\n",
      "\n",
      "        Returns:\n",
      "            str: The final result or an error message if the result wasn't found in time.\n",
      "\n",
      "        Raises:\n",
      "            ValueError: If the agent has not completed its task.\n",
      "        \"\"\"\n",
      "        if not self.completed:\n",
      "            raise ValueError(\"Cannot run an agent further that has not completed.\")\n",
      "        self.completed = False\n",
      "        self.messages.append(OpenAIChatMessage(\"user\", further_instructions))\n",
      "        return self.run()\n",
      "\n",
      "    def setup(self) -> None:\n",
      "        \"\"\"\n",
      "        Sets up the agent by initializing the database and loading the config.\n",
      "\n",
      "        Note: This should be called before running the agent.\n",
      "\n",
      "        Raises:\n",
      "            ValueError: If the config was not properly initialized.\n",
      "        \"\"\"\n",
      "        set_openai_api_key()\n",
      "\n",
      "        if not self.config.session_id:\n",
      "            raise ValueError(\"Config was not properly initialized.\")\n",
      "        self.database_manager: AutomataAgentDatabase = AutomataAgentDatabase(\n",
      "            self.config.session_id\n",
      "        )\n",
      "        self.database_manager._init_database()\n",
      "        if not self.config.is_new_agent:\n",
      "            self.messages = self.database_manager.get_conversations()\n",
      "        else:\n",
      "            if not self.config.system_instruction:\n",
      "                raise ValueError(\"System instruction must be provided if new agent.\")\n",
      "\n",
      "            self._save_message(\"system\", self.config.system_instruction)\n",
      "            initial_messages = self._build_initial_messages(\n",
      "                {\"user_input_instructions\": self.instructions}\n",
      "            )\n",
      "            for message in initial_messages:\n",
      "                self._save_message(message.role, message.content)\n",
      "\n",
      "        logger.debug(\n",
      "            \"Initializing with System Instruction:%s\\n\\n\" % self.config.system_instruction\n",
      "        )\n",
      "        logger.debug(\"-\" * 60)\n",
      "        logger.debug(f\"Session ID: {self.config.session_id}\")\n",
      "        logger.debug(\"-\" * 60)\n",
      "\n",
      "    def _generate_observations(self, response_text: str) -> Dict[str, str]:\n",
      "        \"\"\"\n",
      "        Processes the agent's response text and generates observations.\n",
      "\n",
      "        Args:\n",
      "            response_text (str): The agent's response text.\n",
      "\n",
      "        Returns:\n",
      "            Dict[str, str]: A dictionary of observations.\n",
      "        \"\"\"\n",
      "        outputs = {}\n",
      "        actions = ActionExtractor.extract_actions(response_text)\n",
      "        for action in actions:\n",
      "            if isinstance(action, ToolAction):\n",
      "                (tool_query, tool_name, tool_input) = (\n",
      "                    action.tool_query,\n",
      "                    action.tool_name,\n",
      "                    action.tool_args,\n",
      "                )\n",
      "                # Skip the initializer dummy tool which exists only for providing context\n",
      "                if tool_name == AutomataAgent.INITIALIZER_DUMMY:\n",
      "                    continue\n",
      "                if tool_name == AutomataAgent.ERROR_DUMMY_TOOL:\n",
      "                    # Input becomes the output when an error is registered\n",
      "                    outputs[tool_query.replace(\"query\", \"output\")] = cast(str, tool_input)\n",
      "                else:\n",
      "                    tool_output = self._execute_tool(tool_name, tool_input)\n",
      "                    outputs[tool_query.replace(\"query\", \"output\")] = tool_output\n",
      "            elif isinstance(action, ResultAction):\n",
      "                (result_name, result_outputs) = (action.result_name, action.result_outputs)\n",
      "                # Skip the return result indicator which exists only for marking the return result\n",
      "                outputs[result_name] = \"\\n\".join(result_outputs)\n",
      "            elif isinstance(action, AgentAction):\n",
      "                if action.agent_version.value == AutomataAgent.INITIALIZER_DUMMY:\n",
      "                    continue\n",
      "                agent_output = self._execute_agent(action)\n",
      "                query_name = action.agent_query.replace(\"query\", \"output\")\n",
      "                outputs[query_name] = agent_output\n",
      "\n",
      "        return outputs\n",
      "\n",
      "    def _execute_tool(self, tool_name: str, tool_input: List[str]) -> str:\n",
      "        \"\"\"\n",
      "        Executes a tool with the given name and input.\n",
      "\n",
      "        Args:\n",
      "            tool_name (str): The name of the tool to execute.\n",
      "            tool_input (List[str]): The input arguments for the tool.\n",
      "\n",
      "        Returns:\n",
      "            str: The output of the executed tool.\n",
      "        \"\"\"\n",
      "        tool_found = False\n",
      "        tool_output = None\n",
      "\n",
      "        for toolkit in self.config.llm_toolkits.values():\n",
      "            for tool in toolkit.tools:\n",
      "                if tool.name == tool_name:\n",
      "                    processed_tool_input = [ele if ele != \"None\" else None for ele in tool_input]\n",
      "                    tool_output = tool.run(tuple(processed_tool_input))\n",
      "                    tool_found = True\n",
      "                    break\n",
      "            if tool_found:\n",
      "                break\n",
      "\n",
      "        if not tool_found:\n",
      "            return ToolNotFoundError(tool_name).__str__()\n",
      "\n",
      "        return cast(str, tool_output)\n",
      "\n",
      "    def _has_helper_agents(self) -> bool:\n",
      "        \"\"\"\n",
      "        The existence of a coordinator agent indicates that there are helper agents.\n",
      "\n",
      "        Returns:\n",
      "            bool: True if there are helper agents, False otherwise.\n",
      "        \"\"\"\n",
      "        return self.coordinator is not None\n",
      "\n",
      "    def _extract_outputs(self, pattern: str, messages: list) -> dict:\n",
      "        \"\"\"\n",
      "        Extract outputs from the given messages based on the provided regex pattern.\n",
      "\n",
      "        Args:\n",
      "            pattern (str): The regex pattern to use for extraction.\n",
      "            messages (list): The list of messages to process.\n",
      "\n",
      "        Returns:\n",
      "            dict: A dictionary where the keys are the names of the tools or agents and the values are their outputs.\n",
      "        \"\"\"\n",
      "        outputs = {}\n",
      "        for message in messages:\n",
      "            matches = re.finditer(pattern, message.content, re.DOTALL)\n",
      "            for match in matches:\n",
      "                output_name, output_value = match.group(1), match.group(2).strip()\n",
      "                outputs[output_name] = output_value\n",
      "        return outputs\n",
      "\n",
      "    def _parse_completion_message(self, completion_message: str) -> str:\n",
      "        \"\"\"\n",
      "        Parses the completion message and replaces placeholders with actual tool outputs.\n",
      "\n",
      "        Args:\n",
      "            completion_message (str): The completion message with placeholders.\n",
      "\n",
      "        Returns:\n",
      "            str: The parsed completion message with placeholders replaced by tool outputs.\n",
      "        \"\"\"\n",
      "        tool_pattern = r\"-\\s(tool_output_\\d+)\\s+-\\s(.*?)(?=-\\s(tool_output_\\d+)|$)\"\n",
      "        outputs = self._extract_outputs(tool_pattern, self.messages)\n",
      "\n",
      "        if self._has_helper_agents():\n",
      "            agent_pattern = r\"-\\s(agent_output_\\d+)\\s+-\\s(.*?)(?=-\\s(agent_output_\\d+)|$)\"\n",
      "            agent_outputs = self._extract_outputs(agent_pattern, self.messages)\n",
      "            outputs.update(agent_outputs)\n",
      "\n",
      "        for output_name in outputs:\n",
      "            completion_message = completion_message.replace(\n",
      "                f\"{{{output_name}}}\", outputs[output_name]\n",
      "            )\n",
      "\n",
      "        return completion_message\n",
      "\n",
      "    def _build_initial_messages(self, formatters: Dict[str, str]) -> List[OpenAIChatMessage]:\n",
      "        \"\"\"\n",
      "        Builds the initial messages for the agent's conversation.\n",
      "\n",
      "        Args:\n",
      "            formatters (Dict[str, str]): A dictionary of formatters used to format the messages.\n",
      "\n",
      "        Returns:\n",
      "            List[OpenAIChatMessage]: A list of initial messages for the conversation.\n",
      "        \"\"\"\n",
      "        assert \"user_input_instructions\" in formatters\n",
      "        formatters[\"initializer_dummy_tool\"] = AutomataAgent.INITIALIZER_DUMMY\n",
      "\n",
      "        messages_config = load_config(\n",
      "            ConfigCategory.INSTRUCTION.value, self.config.instruction_version.value\n",
      "        )\n",
      "        initial_messages = messages_config[\"initial_messages\"]\n",
      "\n",
      "        input_messages = []\n",
      "        for message in initial_messages:\n",
      "            input_message = format_text(formatters, message[\"content\"])\n",
      "            input_messages.append(OpenAIChatMessage(role=message[\"role\"], content=input_message))\n",
      "\n",
      "        return input_messages\n",
      "\n",
      "    def _stream_message(self, response_summary: Any):\n",
      "        \"\"\"\n",
      "        Streams the response message from the agent.\n",
      "\n",
      "        Args:\n",
      "            response_summary (Any): The response summary from the agent.\n",
      "\n",
      "        Returns:\n",
      "            str: The streamed response text.\n",
      "        \"\"\"\n",
      "        print(colored(f\"\\n>>> {self.config.config_name.value} Agent:\", \"green\"))\n",
      "        latest_accumulation = \"\"\n",
      "        stream_separator = \" \"\n",
      "        response_text = \"\"\n",
      "        for chunk in response_summary:\n",
      "            if \"content\" in chunk[\"choices\"][0][\"delta\"]:\n",
      "                chunk_content = chunk[\"choices\"][0][\"delta\"][\"content\"]\n",
      "                chunk_content.replace(\"\\\\n\", \"\\n\")\n",
      "                latest_accumulation += chunk_content\n",
      "                response_text += chunk_content\n",
      "            if stream_separator in latest_accumulation:\n",
      "                words = latest_accumulation.split(stream_separator)\n",
      "                for word in words[:-1]:\n",
      "                    print(colored(str(word), \"green\"), end=\" \", flush=True)\n",
      "                latest_accumulation = words[-1]\n",
      "        print(colored(str(latest_accumulation), \"green\"))\n",
      "        return response_text\n",
      "\n",
      "    def _save_message(self, role: str, content: str) -> OpenAIChatMessage:\n",
      "        \"\"\"\n",
      "        Saves the messagee for the agent.\n",
      "\n",
      "        Args:\n",
      "            role (str): The role of the messagee.\n",
      "            content (str): The content of the messagee.\n",
      "        \"\"\"\n",
      "        self.database_manager.put_message(role, content, len(self.messages))\n",
      "        message = OpenAIChatMessage(role=role, content=content)\n",
      "        self.messages.append(message)\n",
      "        return message\n",
      "\n",
      "    def _execute_agent(self, agent_action: AgentAction) -> str:\n",
      "        \"\"\"\n",
      "        Generate the result from the specified agent_action using the coordinator.\n",
      "\n",
      "        Args:\n",
      "            agent_action (AgentAction): An instance of an AgentAction to be executed.\n",
      "\n",
      "        Returns:\n",
      "            str: The output generated by the agent.\n",
      "        \"\"\"\n",
      "        if not self.coordinator:\n",
      "            raise Exception(\"Agent has no coordinator.\")\n",
      "\n",
      "        return self.coordinator.run_agent(agent_action)\n",
      "\n",
      "    def _get_debug_summary(self):\n",
      "        \"\"\"Get the debug summary for the agent.\"\"\"\n",
      "        user_message = \"Provide a succinct one-sentence summary of the errors encountered. Write nothing else.\"\n",
      "        self._save_message(\"user\", user_message)\n",
      "        return self._get_openai_response()\n",
      "\n",
      "    def _get_openai_response(self) -> str:\n",
      "        \"\"\"Get the response from OpenAI.\"\"\"\n",
      "        response_summary = openai.ChatCompletion.create(\n",
      "            model=self.config.model,\n",
      "            messages=[ele.to_dict() for ele in self.messages],\n",
      "            temperature=self.config.temperature,\n",
      "            stream=self.config.stream,\n",
      "        )\n",
      "        return (\n",
      "            self._stream_message(response_summary)\n",
      "            if self.config.stream\n",
      "            else OpenAIChatCompletionResult(raw_data=response_summary).get_completion()\n",
      "        )\n",
      "\n",
      "\n",
      "--->Vector<---\n",
      "\n",
      "[-0.0383666  -0.00689272  0.0076008  ... -0.02022319  0.00478556\n",
      " -0.04397655]\n",
      "\n",
      "--->Symbol DotPath<---\n",
      "automata.core.coding.py_coding.writer.PyCodeWriter\n",
      "\n",
      "Integer Rank=2, Rank Score=0.004\n",
      "\n",
      "--->Documentation Code<---\n",
      "\n",
      "class PyCodeWriter:\n",
      "    \"\"\"A utility class for writing Python code along AST nodes\"\"\"\n",
      "\n",
      "    class ModuleNotFound(Exception):\n",
      "        \"\"\"Raised when a module is not found in the module dictionary\"\"\"\n",
      "\n",
      "        pass\n",
      "\n",
      "    class ClassOrFunctionNotFound(Exception):\n",
      "        \"\"\"Raised when a class or function is not found in the module\"\"\"\n",
      "\n",
      "        pass\n",
      "\n",
      "    class InvalidArguments(Exception):\n",
      "        \"\"\"Raised when invalid arguments are passed to a method\"\"\"\n",
      "\n",
      "        pass\n",
      "\n",
      "    def __init__(self, py_retriever: PyCodeRetriever) -> None:\n",
      "        \"\"\"\n",
      "        Initialize the PyCodeWriter with a PyCodeRetriever instance\n",
      "\n",
      "        Args:\n",
      "            py_retriever (PyCodeRetriever): The PyCodeRetriever instance to use\n",
      "        \"\"\"\n",
      "        self.code_retriever = py_retriever\n",
      "\n",
      "    def create_new_module(\n",
      "        self, module_dotpath: str, source_code: str, do_write: bool = False\n",
      "    ) -> None:\n",
      "        \"\"\"\n",
      "        Create a new module object from source code\n",
      "\n",
      "        Args:\n",
      "            source_code (str): The source code of the module\n",
      "            module_dotpath (str): The path of the module\n",
      "\n",
      "        Returns:\n",
      "            RedBaron: The created module object\n",
      "        \"\"\"\n",
      "        self._create_module_from_source_code(module_dotpath, source_code)\n",
      "        if do_write:\n",
      "            self._write_module_to_disk(module_dotpath)\n",
      "\n",
      "    def update_existing_module(\n",
      "        self,\n",
      "        module_dotpath: str,\n",
      "        source_code: str,\n",
      "        disambiguator: Optional[str] = \"\",\n",
      "        do_write: bool = False,\n",
      "    ) -> None:\n",
      "        \"\"\"\n",
      "        Update code or insert new code into an existing module\n",
      "\n",
      "        Args:\n",
      "            source_code (str): The source code of the part of the module that needs to be\n",
      "            updated or insert module_dotpath (str): The path of the module\n",
      "            disambiguator (Optional[str]): The name of the class or function scope where\n",
      "                the update should be applied, will default to module\n",
      "            do_write (bool): Write the module to disk after updating\n",
      "\n",
      "        Returns:\n",
      "            RedBaron: The updated module object\n",
      "\n",
      "        Raises:\n",
      "            ModuleNotFound: If the module is not found in the module dictionary\n",
      "        \"\"\"\n",
      "        module_obj = self.code_retriever.module_tree_map.fetch_module(module_dotpath)\n",
      "        if not module_obj:\n",
      "            raise PyCodeWriter.ModuleNotFound(\n",
      "                f\"Module not found in module dictionary: {module_dotpath}\"\n",
      "            )\n",
      "        PyCodeWriter._update_existing_module(\n",
      "            source_code,\n",
      "            module_dotpath,\n",
      "            module_obj,\n",
      "            disambiguator=disambiguator,\n",
      "        )\n",
      "        if do_write:\n",
      "            self._write_module_to_disk(module_dotpath)\n",
      "\n",
      "    def delete_from_existing__module(\n",
      "        self, module_dotpath: str, object_dotpath: str, do_write: bool = False\n",
      "    ) -> None:\n",
      "        \"\"\"\n",
      "        Reduce an existing module by removing a class or function\n",
      "\n",
      "        Args:\n",
      "            module_dotpath (str): The path of the module\n",
      "            object_dotpath (str): The name of the class or function to remove, including\n",
      "                the name of the scope it is in, like ClassName.function_name\n",
      "            do_write (bool): Write the module to disk after updating\n",
      "\n",
      "        Returns:\n",
      "            RedBaron: The module object\n",
      "\n",
      "        Raises:\n",
      "            ModuleNotFound: If the module is not found in the module dictionary\n",
      "        \"\"\"\n",
      "        module_obj = self.code_retriever.module_tree_map.fetch_module(module_dotpath)\n",
      "        if not module_obj:\n",
      "            raise PyCodeWriter.ModuleNotFound(\n",
      "                f\"Module not found in module dictionary: {module_dotpath}\"\n",
      "            )\n",
      "        node = find_syntax_tree_node(module_obj, object_dotpath)\n",
      "        if node:\n",
      "            PyCodeWriter._delete_node(node)\n",
      "            if do_write:\n",
      "                self._write_module_to_disk(module_dotpath)\n",
      "\n",
      "    def _write_module_to_disk(self, module_dotpath: str) -> None:\n",
      "        \"\"\"\n",
      "        Write the modified module to a file at the specified output path\n",
      "\n",
      "        Args:\n",
      "            module_dotpath (str)\n",
      "\n",
      "        Raises:\n",
      "            ModuleNotFound: If the module is not found in the module dictionary\n",
      "        \"\"\"\n",
      "        if module_dotpath not in self.code_retriever.module_tree_map:\n",
      "            raise PyCodeWriter.ModuleNotFound(\n",
      "                f\"Module not found in module dictionary: {module_dotpath}\"\n",
      "            )\n",
      "        source_code = self.code_retriever.get_source_code(module_dotpath)\n",
      "        module_fpath = self.code_retriever.module_tree_map.fetch_existing_module_fpath_by_dotpath(\n",
      "            module_dotpath\n",
      "        )\n",
      "\n",
      "        if not module_fpath:\n",
      "            raise PyCodeWriter.ModuleNotFound(\n",
      "                f\"Module fpath found in module map for dotpath: {module_dotpath}\"\n",
      "            )\n",
      "        module_fpath = cast(str, module_fpath)\n",
      "        with open(module_fpath, \"w\") as output_file:\n",
      "            output_file.write(source_code)\n",
      "        subprocess.run([\"black\", module_fpath])\n",
      "        subprocess.run([\"isort\", module_fpath])\n",
      "\n",
      "    def _create_module_from_source_code(self, module_dotpath: str, source_code: str) -> RedBaron:\n",
      "        \"\"\"\n",
      "        Create a Python module from the given source code string\n",
      "\n",
      "        Args:\n",
      "            module_dotpath (str): The path where the new module will be created\n",
      "\n",
      "        Returns:\n",
      "            RedBaron: The created module object\n",
      "        \"\"\"\n",
      "        parsed = RedBaron(source_code)\n",
      "        self.code_retriever.module_tree_map.put_module(module_dotpath, parsed)\n",
      "        return parsed\n",
      "\n",
      "    @staticmethod\n",
      "    def _update_existing_module(\n",
      "        source_code: str,\n",
      "        module_dotpath: str,\n",
      "        existing_module_obj: RedBaron,\n",
      "        disambiguator: Optional[str],\n",
      "    ) -> None:\n",
      "        \"\"\"\n",
      "        Update a module object according to the received code\n",
      "\n",
      "        Args:\n",
      "            source_code (str): The code containing the updates\n",
      "            module_dotpath (str): The relative path to the module\n",
      "            existing_module_obj Module: The module object to be updated\n",
      "            disambiguator (str): The name of the class or function scope to\n",
      "                be updated, useful for nested definitions\n",
      "\n",
      "        Raises:\n",
      "            ClassOrFunctionNotFound: If the disambiguator is not found\n",
      "        \"\"\"\n",
      "\n",
      "        new_fst = RedBaron(source_code)\n",
      "        new_import_nodes = find_import_syntax_tree_nodes(new_fst)\n",
      "        PyCodeWriter._update_imports(existing_module_obj, new_import_nodes)\n",
      "\n",
      "        new_class_or_function_nodes = find_all_function_and_class_syntax_tree_nodes(new_fst)\n",
      "        if disambiguator:  # splice the class\n",
      "            disambiguator_node = find_syntax_tree_node(existing_module_obj, disambiguator)\n",
      "            if isinstance(disambiguator_node, (ClassNode, DefNode)):\n",
      "                PyCodeWriter._update_node_with_children(\n",
      "                    new_class_or_function_nodes,\n",
      "                    disambiguator_node,\n",
      "                )\n",
      "            else:\n",
      "                raise PyCodeWriter.ClassOrFunctionNotFound(\n",
      "                    f\"Node {disambiguator} not found in module {module_dotpath}\"\n",
      "                )\n",
      "        PyCodeWriter._update_node_with_children(new_class_or_function_nodes, existing_module_obj)\n",
      "\n",
      "    @staticmethod\n",
      "    def _update_node_with_children(\n",
      "        class_or_function_nodes: NodeList,\n",
      "        node_to_update: Union[ClassNode, RedBaron],\n",
      "    ) -> None:\n",
      "        \"\"\"\n",
      "        Update a class object according to the received code\n",
      "\n",
      "        Args:\n",
      "            class_or_function_nodes (NodeList): The nodes to update\n",
      "            node_to_update (Union[ClassNode, RedBaron]): The node to update\n",
      "        \"\"\"\n",
      "        for new_node in class_or_function_nodes:\n",
      "            child_node_name = new_node.name\n",
      "            existing_node = find_syntax_tree_node(node_to_update, child_node_name)\n",
      "            if existing_node:\n",
      "                existing_node.replace(new_node)\n",
      "            else:\n",
      "                node_to_update.append(new_node)\n",
      "\n",
      "    @staticmethod\n",
      "    def _delete_node(node: Node) -> None:\n",
      "        \"\"\"\n",
      "        Delete a node from the FST\n",
      "\n",
      "        Args:\n",
      "            node (Node): The node to delete\n",
      "        \"\"\"\n",
      "        parent = node.parent\n",
      "        parent_index = node.index_on_parent\n",
      "        parent.pop(parent_index)\n",
      "\n",
      "    @staticmethod\n",
      "    def _clean_input_code(source_code: str) -> str:\n",
      "        \"\"\"\n",
      "        Take the input source code and remove formatting issues that will cause the FST to fail.\n",
      "\n",
      "        Args:\n",
      "            source_code (str): The source code to clean.\n",
      "\n",
      "        Returns:\n",
      "            str: The cleaned source code.\n",
      "        \"\"\"\n",
      "\n",
      "        def replace_newline_chars(input_str: str) -> str:\n",
      "            dummy_replacement_a = \"ZZ_^^_ZZ\"\n",
      "            dummy_replacement_b = \"QQ_^^_QQ\"\n",
      "\n",
      "            def replace(match):\n",
      "                text = match.group(0)\n",
      "                if text[0] == '\"' and text[-1] == '\"':\n",
      "                    return text\n",
      "                return text.replace(\"\\\\n\", \"\\n\")\n",
      "\n",
      "            pattern = \"(?x)\\n                '.*?'\\n                |\\n                \\\".*?\\\"\\n                |\\n                [^'\\\"]+\\n            \"\n",
      "            output_str = (\n",
      "                \"\".join(\n",
      "                    (\n",
      "                        replace(match)\n",
      "                        for match in re.finditer(\n",
      "                            pattern,\n",
      "                            input_str.replace('\"\"\"', dummy_replacement_a).replace(\n",
      "                                \"'''\", dummy_replacement_b\n",
      "                            ),\n",
      "                        )\n",
      "                    )\n",
      "                )\n",
      "                .replace(dummy_replacement_a, '\"\"\"')\n",
      "                .replace(dummy_replacement_b, \"'''\")\n",
      "            )\n",
      "            return output_str\n",
      "\n",
      "        source_code = replace_newline_chars(source_code)\n",
      "        source_code = re.sub('\\\\\\\\\\\\\"', '\"', source_code)\n",
      "        source_code = source_code.strip()\n",
      "        return source_code\n",
      "\n",
      "    @staticmethod\n",
      "    def _update_imports(module_obj: RedBaron, new_import_statements: NodeList) -> None:\n",
      "        \"\"\"\n",
      "        Manage the imports in the module\n",
      "\n",
      "        Args:\n",
      "            module_obj (RedBaron): The module object\n",
      "            new_import_statements (NodeList): The new import statements\n",
      "\n",
      "        \"\"\"\n",
      "        first_import = module_obj.find(lambda identifier: identifier in (\"import\", \"from_import\"))\n",
      "\n",
      "        for new_import_statement in new_import_statements:\n",
      "            existing_import_statement = find_import_syntax_tree_node_by_name(\n",
      "                module_obj, new_import_statement.name\n",
      "            )\n",
      "            if not existing_import_statement:\n",
      "                if first_import:\n",
      "                    first_import.insert_before(new_import_statement)  # we will run isort later\n",
      "                else:\n",
      "                    module_obj.insert(0, new_import_statement)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "--->Vector<---\n",
      "\n",
      "[-0.01144696  0.00763573 -0.02248225 ... -0.01399663  0.01459421\n",
      " -0.0398386 ]\n",
      "\n",
      "--->Symbol DotPath<---\n",
      "automata.core.symbol.graph.SymbolGraph\n",
      "\n",
      "Integer Rank=3, Rank Score=0.003\n",
      "\n",
      "--->Documentation Code<---\n",
      "\n",
      "class SymbolGraph:\n",
      "    @dataclass\n",
      "    class SubGraph:\n",
      "        parent: \"SymbolGraph\"\n",
      "        graph: nx.DiGraph\n",
      "\n",
      "    def __init__(self, index_path: str, build_caller_relationships: bool = False) -> None:\n",
      "        \"\"\"\n",
      "        Initializes SymbolGraph with the path of an index protobuf file.\n",
      "\n",
      "        Args:\n",
      "            index_path (str): Path to index protobuf file\n",
      "\n",
      "        Returns:\n",
      "            SymbolGraph instance\n",
      "        \"\"\"\n",
      "        index = self._load_index_protobuf(index_path)\n",
      "        builder = GraphBuilder(index, build_caller_relationships)\n",
      "        self._graph = builder.build_graph()\n",
      "        self.navigator = _SymbolGraphNavigator(self._graph)\n",
      "\n",
      "    def get_all_files(self) -> List[SymbolFile]:\n",
      "        \"\"\"\n",
      "        Gets all file nodes in the graph.\n",
      "\n",
      "        Args:\n",
      "            None\n",
      "\n",
      "        Returns:\n",
      "            List of all defined symbols.\n",
      "        \"\"\"\n",
      "        return self.navigator.get_all_files()\n",
      "\n",
      "    def get_all_available_symbols(self) -> List[Symbol]:\n",
      "        \"\"\"\n",
      "        Gets all symbols defined in the graph.\n",
      "\n",
      "        Args:\n",
      "            None\n",
      "\n",
      "        Returns:\n",
      "            List[Symbol]: List of all defined symbols.\n",
      "        \"\"\"\n",
      "        return list(set(self.navigator.get_all_available_symbols()))\n",
      "\n",
      "    def get_symbol_dependencies(self, symbol: Symbol) -> Set[Symbol]:\n",
      "        \"\"\"\n",
      "        Gets all symbols which contain a specified partial path\n",
      "\n",
      "        Args:\n",
      "            partial_py_path (PyPath): The partial path to explain\n",
      "\n",
      "        Returns:\n",
      "            Set[Symbol]: Set of symbols that follow the partial path\n",
      "        \"\"\"\n",
      "        return self.navigator.get_symbol_dependencies(symbol)\n",
      "\n",
      "    def get_symbol_relationships(self, symbol: Symbol) -> Set[Symbol]:\n",
      "        \"\"\"\n",
      "        Gets the set of symbols with relationships to the given symbol.\n",
      "\n",
      "        Args:\n",
      "            symbol (Symbol): The symbol to get relationships for.\n",
      "\n",
      "        Returns:\n",
      "            Set[Symbol]: The list of relationships for the symbol.\n",
      "\n",
      "        # TODO: Consider implications of using list instead of set\n",
      "        \"\"\"\n",
      "        return self.navigator.get_symbol_relationships(symbol)\n",
      "\n",
      "    def get_potential_symbol_callers(self, symbol: Symbol) -> Dict[SymbolReference, Symbol]:\n",
      "        \"\"\"\n",
      "        Gets the (potential) callers of the given symbol.\n",
      "        Requires downstream filtering to remove non-call statements.\n",
      "\n",
      "        Args:\n",
      "            symbol (Symbol): The symbol to get callers for.\n",
      "\n",
      "        Returns:\n",
      "            Dict[Symbol]: The map of callers to callees for the symbol.\n",
      "        \"\"\"\n",
      "\n",
      "        return self.navigator.get_potential_symbol_callers(symbol)\n",
      "\n",
      "    def get_potential_symbol_callees(self, symbol: Symbol) -> Dict[Symbol, SymbolReference]:\n",
      "        \"\"\"\n",
      "        Gets the callers of the given symbol.\n",
      "        Requires downstream filtering to remove non-call statements.\n",
      "\n",
      "        Args:\n",
      "            symbol (Symbol): The symbol to get callees for.\n",
      "\n",
      "        Returns:\n",
      "            Dict[Symbol]: The map of callees to callers for the symbol.\n",
      "        \"\"\"\n",
      "        return self.navigator.get_potential_symbol_callees(symbol)\n",
      "\n",
      "    def get_references_to_symbol(self, symbol: Symbol) -> Dict[str, List[SymbolReference]]:\n",
      "        \"\"\"\n",
      "        Gets all references to a given module in the symbol graph.\n",
      "\n",
      "        Args:\n",
      "            module (Symbol): The module to locate references for\n",
      "\n",
      "        Returns:\n",
      "            List[SymbolReference]: List of symbol references\n",
      "        \"\"\"\n",
      "        return self.navigator.get_references_to_symbol(symbol)\n",
      "\n",
      "    def get_rankable_symbol_subgraph(\n",
      "        self, flow_rank=\"bidirectional\", path_filter: Optional[str] = None\n",
      "    ) -> SubGraph:\n",
      "        \"\"\"\n",
      "        Gets a detailed subgraph of rankable symbols.\n",
      "\n",
      "        Args:\n",
      "            symbol (str): The symbol in the form 'module`/ClassOrMethod#'\n",
      "\n",
      "        Returns:\n",
      "            List[str]: The list of dependencies for the symbol.\n",
      "        TODO: Find ways to better handle edge cases\n",
      "        \"\"\"\n",
      "        G = nx.DiGraph()\n",
      "\n",
      "        filtered_symbols = get_rankable_symbols(self.get_all_available_symbols())\n",
      "\n",
      "        if path_filter is not None:\n",
      "            filtered_symbols = [\n",
      "                sym for sym in filtered_symbols if sym.dotpath.startswith(path_filter)  # type: ignore\n",
      "            ]\n",
      "\n",
      "        self.navigator._pre_compute_rankable_bounding_boxes()\n",
      "\n",
      "        logger.info(\"Building the rankable symbol subgraph...\")\n",
      "        for symbol in tqdm(filtered_symbols):\n",
      "            try:\n",
      "                dependencies = self.get_symbol_dependencies(symbol)\n",
      "                relationships = self.get_symbol_relationships(symbol)\n",
      "                filtered_related_symbols = get_rankable_symbols(\n",
      "                    list(dependencies.union(relationships))\n",
      "                )\n",
      "                for dependency in filtered_related_symbols:\n",
      "                    if flow_rank == \"to_dependents\":\n",
      "                        G.add_edge(symbol, dependency)\n",
      "                    elif flow_rank == \"from_dependents\":\n",
      "                        G.add_edge(dependency, symbol)\n",
      "                    elif flow_rank == \"bidirectional\":\n",
      "                        G.add_edge(symbol, dependency)\n",
      "                        G.add_edge(dependency, symbol)\n",
      "                    else:\n",
      "                        raise ValueError(\n",
      "                            \"flow_rank must be one of 'to_dependents', 'from_dependents', or 'bidirectional'\"\n",
      "                        )\n",
      "\n",
      "            except Exception as e:\n",
      "                logger.error(f\"Error processing {symbol.uri}: {e}\")\n",
      "\n",
      "        logger.info(\"Built the rankable symbol subgraph\")\n",
      "\n",
      "        return SymbolGraph.SubGraph(graph=G, parent=self)\n",
      "\n",
      "    @staticmethod\n",
      "    def _load_index_protobuf(path: str) -> Index:\n",
      "        \"\"\"\n",
      "        Loads an index protobuf file from disk\n",
      "\n",
      "        Args:\n",
      "            path (str): The path to the index protobuf file\n",
      "\n",
      "        Returns:\n",
      "            Index: The loaded index protobuf\n",
      "        \"\"\"\n",
      "        index = Index()\n",
      "        with open(path, \"rb\") as f:\n",
      "            index.ParseFromString(f.read())\n",
      "        return index\n",
      "\n",
      "\n",
      "--->Vector<---\n",
      "\n",
      "[-0.00702063 -0.014918   -0.02853416 ... -0.01521025 -0.02140062\n",
      " -0.05451778]\n",
      "\n",
      "--->Symbol DotPath<---\n",
      "automata.core.database.vector.JSONVectorDatabase\n",
      "\n",
      "Integer Rank=4, Rank Score=0.003\n",
      "\n",
      "--->Documentation Code<---\n",
      "\n",
      "class JSONVectorDatabase(VectorDatabaseProvider):\n",
      "    \"\"\"\n",
      "    Concrete class to provide a vector database that saves into a JSON file.\n",
      "    \"\"\"\n",
      "\n",
      "    def __init__(self, file_path: str):\n",
      "        \"\"\"\n",
      "        Args:\n",
      "            file_path: The path to the JSON file to save the vector database to\n",
      "        \"\"\"\n",
      "        self.file_path = file_path\n",
      "        self.data: List[SymbolEmbedding] = []\n",
      "        self.index: Dict[str, int] = {}\n",
      "        self.load()\n",
      "\n",
      "    def save(self):\n",
      "        \"\"\"Saves the vector database to the JSON file\"\"\"\n",
      "        with open(self.file_path, \"w\") as file:\n",
      "            encoded_data = jsonpickle.encode(self.data)\n",
      "            file.write(encoded_data)\n",
      "\n",
      "    def load(self):\n",
      "        \"\"\"Loads the vector database from the JSON file\"\"\"\n",
      "        try:\n",
      "            with open(self.file_path, \"r\") as file:\n",
      "                self.data = jsonpickle.decode(file.read())\n",
      "                # We index on the dotpath of the symbol, which is unique and indepenent of commit hash\n",
      "                self.index = {embedding.symbol.dotpath: i for i, embedding in enumerate(self.data)}\n",
      "        except FileNotFoundError:\n",
      "            logger.info(f\"Creating new vector embedding db at {self.file_path}\")\n",
      "\n",
      "    def add(self, embedding: SymbolEmbedding):\n",
      "        \"\"\"\n",
      "        Adds a new vector to the database\n",
      "\n",
      "        Args:\n",
      "            embedding: The vector to add\n",
      "        \"\"\"\n",
      "        self.data.append(embedding)\n",
      "        self.index[embedding.symbol.dotpath] = len(self.data) - 1\n",
      "\n",
      "    def update(self, embedding: SymbolEmbedding):\n",
      "        \"\"\"\n",
      "        Updates an embedding in the database\n",
      "\n",
      "        Args:\n",
      "            embedding: The vector to update\n",
      "\n",
      "        Raises:\n",
      "            KeyError: If the symbol is not in the database\n",
      "        \"\"\"\n",
      "        if embedding.symbol not in self.index:\n",
      "            raise KeyError(f\"Symbol {embedding.symbol} not in database\")\n",
      "        self.data[self.index[embedding.symbol.dotpath]] = embedding\n",
      "\n",
      "    def discard(self, symbol: Symbol):\n",
      "        \"\"\"\n",
      "        Discards a vector from the database\n",
      "\n",
      "        Args:\n",
      "            symbol: The symbol to discard\n",
      "\n",
      "        Raises:\n",
      "            KeyError: If the symbol is not in the database\n",
      "        \"\"\"\n",
      "        if symbol.dotpath not in self.index:\n",
      "            raise KeyError(f\"Symbol {symbol} not in database\")\n",
      "        index = self.index[symbol.dotpath]\n",
      "        del self.data[index]\n",
      "        del self.index[symbol.dotpath]\n",
      "        # Recalculate indices after deletion\n",
      "        self.index = {embedding.symbol.dotpath: i for i, embedding in enumerate(self.data)}\n",
      "\n",
      "    def contains(self, symbol: Symbol) -> bool:\n",
      "        \"\"\"\n",
      "        Checks if the database contains a vector for the given symbol\n",
      "\n",
      "        Args:\n",
      "            symbol: The symbol to check\n",
      "\n",
      "        Returns:\n",
      "            True if the database contains a vector for the given symbol, False otherwise\n",
      "        \"\"\"\n",
      "        return symbol.dotpath in self.index\n",
      "\n",
      "    def get(self, symbol: Symbol) -> SymbolEmbedding:\n",
      "        \"\"\"\n",
      "        Gets the vector for the given symbol\n",
      "\n",
      "        Args:\n",
      "            symbol: The symbol to get the vector for\n",
      "\n",
      "        Raises:\n",
      "            KeyError: If the symbol is not in the database\n",
      "        \"\"\"\n",
      "        if symbol.dotpath not in self.index:\n",
      "            raise KeyError(f\"Symbol {symbol} not in database\")\n",
      "        return self.data[self.index[symbol.dotpath]]\n",
      "\n",
      "    def clear(self):\n",
      "        \"\"\"Removes all vectors from the database\"\"\"\n",
      "        self.data = []\n",
      "        self.index = {}\n",
      "\n",
      "    def calculate_similarity(self, embedding: SymbolEmbedding) -> List[Dict[Symbol, float]]:\n",
      "        # Implement the logic to calculate similarity between the given vector and vectors in the data.\n",
      "        # This will depend on how the data is structured and the specific similarity measure to be used (e.g., cosine similarity).\n",
      "        # Here, just returning the data as a placeholder.\n",
      "        # return self.data\n",
      "        raise NotImplementedError\n",
      "\n",
      "    def get_all_symbols(self) -> List[Symbol]:\n",
      "        \"\"\"\n",
      "        Gets all symbols in the database\n",
      "\n",
      "        Returns:\n",
      "            A list of all symbols in the database\n",
      "        \"\"\"\n",
      "        symbol_list = [embedding.symbol for embedding in self.data]\n",
      "        return sorted(symbol_list, key=lambda x: str(x.dotpath))\n",
      "\n",
      "\n",
      "--->Vector<---\n",
      "\n",
      "[-0.0219451   0.00040082 -0.01313965 ... -0.00917099 -0.0182506\n",
      " -0.04331579]\n",
      "\n",
      "--->Symbol DotPath<---\n",
      "automata.core.base.tool.Tool\n",
      "\n",
      "Integer Rank=5, Rank Score=0.003\n",
      "\n",
      "--->Documentation Code<---\n",
      "\n",
      "class Tool(BaseTool):\n",
      "    \"\"\"Tool that takes in function or coroutine directly.\"\"\"\n",
      "\n",
      "    description: str = \"\"\n",
      "    func: Callable[..., str]\n",
      "    coroutine: Optional[Callable[..., Awaitable[str]]] = None\n",
      "\n",
      "    def _run(self, tool_input: Tuple[Optional[str], ...]) -> str:\n",
      "        \"\"\"Use the tool.\"\"\"\n",
      "        return self.func(tool_input)\n",
      "\n",
      "    async def _arun(self, tool_input: Tuple[Optional[str], ...]) -> str:\n",
      "        \"\"\"Use the tool asynchronously.\"\"\"\n",
      "        if self.coroutine:\n",
      "            return await self.coroutine(tool_input)\n",
      "        raise NotImplementedError(\"Tool does not support async\")\n",
      "\n",
      "    # TODO: this is for backwards compatibility, remove in future\n",
      "    def __init__(self, name: str, func: Callable[[str], str], description: str, **kwargs: Any):\n",
      "        \"\"\"Initialize tool.\"\"\"\n",
      "        super(Tool, self).__init__(name=name, func=func, description=description, **kwargs)  # type: ignore\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "--->Vector<---\n",
      "\n",
      "[-0.03351887 -0.0226013  -0.00410093 ...  0.01585648 -0.00945369\n",
      " -0.03433974]\n",
      "\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Symbol Symbol(scip-python python automata 9db05b7e7ebd49f93703df45accd7e5f9d5cedb0 posixpath/join()., scip-python, Package(python automata 9db05b7e7ebd49f93703df45accd7e5f9d5cedb0), (Descriptor(posixpath, 1), Descriptor(join, 4))) not in database'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPrinting out Code Embeddings for top ten ranked symbols\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ir, (symbol, rank) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(ranks[\u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m10\u001b[39m]):\n\u001b[0;32m---> 11\u001b[0m     symbol_code_embedding \u001b[38;5;241m=\u001b[39m \u001b[43membedding_code_db\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43msymbol\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--->Symbol DotPath<---\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msymbol\u001b[38;5;241m.\u001b[39mdotpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mInteger Rank=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Rank Score=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrank\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--->Documentation Code<---\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msymbol_code_embedding\u001b[38;5;241m.\u001b[39membedding_source\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/_Automata_/automata/core/database/vector.py:130\u001b[0m, in \u001b[0;36mJSONVectorDatabase.get\u001b[0;34m(self, symbol)\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;124;03mGets the vector for the given symbol\u001b[39;00m\n\u001b[1;32m    122\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;124;03m    KeyError: If the symbol is not in the database\u001b[39;00m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m symbol\u001b[38;5;241m.\u001b[39mdotpath \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex:\n\u001b[0;32m--> 130\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSymbol \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msymbol\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in database\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex[symbol\u001b[38;5;241m.\u001b[39mdotpath]]\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Symbol Symbol(scip-python python automata 9db05b7e7ebd49f93703df45accd7e5f9d5cedb0 posixpath/join()., scip-python, Package(python automata 9db05b7e7ebd49f93703df45accd7e5f9d5cedb0), (Descriptor(posixpath, 1), Descriptor(join, 4))) not in database'"
     ]
    }
   ],
   "source": [
    "embedding_code_fpath = os.path.join(\n",
    "    config_fpath(),\n",
    "    ConfigCategory.SYMBOL.value,\n",
    "    \"symbol_code_embedding.json\"\n",
    ")\n",
    "\n",
    "embedding_code_db = JSONVectorDatabase(embedding_code_fpath)\n",
    "\n",
    "print(\"Printing out Code Embeddings for top ten ranked symbols\\n\")\n",
    "for ir, (symbol, rank) in enumerate(ranks[0:10]):\n",
    "    symbol_code_embedding = embedding_code_db.get(symbol)\n",
    "    print(f\"--->Symbol DotPath<---\\n{symbol.dotpath}\\n\\nInteger Rank={ir}, Rank Score={rank:.3f}\\n\")\n",
    "    print(f\"--->Documentation Code<---\\n\\n{symbol_code_embedding.embedding_source}\\n\")\n",
    "    print(f\"--->Vector<---\\n\\n{symbol_code_embedding.vector}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7cbbe4e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing out Documentation Embeddings for top ten ranked symbols\n",
      "\n",
      "--->Symbol DotPath<---\n",
      "automata.core.symbol.symbol_types.Symbol\n",
      "\n",
      "Integer Rank=0, Rank Score=0.006\n",
      "\n",
      "--->Documentation Code<---\n",
      "\n",
      "# Symbol\n",
      "\n",
      "`Symbol` is similar to a URI, it identifies a class, method, or a local variable. `Symbol` has a standardized string representation, which can be used interchangeably with the URI and can be parsed using `automata.core.symbol.parser.parse_symbol`.\n",
      "\n",
      "## Overview\n",
      "\n",
      "`Symbol` has a standardized string representation that can be used to identify a class, method, or local variable. It also allows for metadata queries like determining if the symbol is local, meta, or a parameter. It can be initialized by passing its URI, scheme, package, and descriptors and offers various utility methods deriving more information about the symbol and related operations.\n",
      "\n",
      "## Related Symbols\n",
      "\n",
      "- `automata.core.symbol.parser.parse_symbol`\n",
      "- `automata.tests.unit.test_symbol_parser.test_parse_symbol`\n",
      "\n",
      "## Example\n",
      "\n",
      "```python\n",
      "from automata.core.symbol.parser import parse_symbol\n",
      "\n",
      "symbol_class = parse_symbol(\n",
      "  \"scip-python python automata 75482692a6fe30c72db516201a6f47d9fb4af065 `automata.core.agent.agent_enums`/ActionIndicator#\"\n",
      ")\n",
      "\n",
      "symbol_method = parse_symbol(\n",
      "  \"scip-python python automata 75482692a6fe30c72db516201a6f47d9fb4af065 `automata.core.base.tool`/ToolNotFoundError#__init__().\"\n",
      ")\n",
      "```\n",
      "\n",
      "## Methods Overview\n",
      "\n",
      "- `__eq__(self, other)` compares the URI string.\n",
      "- `__hash__(self)` returns a hash of the URI string.\n",
      "- `__repr__(self)` returns a string representation of the object.\n",
      "- `is_local(symbol)` indicates whether the symbol is a local symbol.\n",
      "- `is_meta(symbol)` indicates whether the symbol is a meta symbol.\n",
      "- `is_parameter(symbol)` indicates whether the symbol is a parameter.\n",
      "- `is_protobuf(symbol)` indicates whether the symbol is a protobuf symbol.\n",
      "- `parent(self)` returns the parent symbol of the current symbol.\n",
      "\n",
      "## Limitations\n",
      "\n",
      "`Symbol` assumes an expected syntax for its string representation, and any deviations from the syntax may lead to unexpected results. Parsing from a string representation to a `Symbol` object requires the usage of the `automata.core.symbol.parser.parse_symbol` method, adding an extra dependency.\n",
      "\n",
      "## Follow-up Questions:\n",
      "\n",
      "- Can we include more examples for methods like `is_local`, `is_meta`, and others?\n",
      "\n",
      "--->Vector<---\n",
      "\n",
      "[ 0.00400109  0.02000894  0.01970089 ... -0.0088773  -0.02408354\n",
      " -0.02664591]\n",
      "\n",
      "--->Symbol DotPath<---\n",
      "automata.core.agent.agent.AutomataAgent\n",
      "\n",
      "Integer Rank=1, Rank Score=0.004\n",
      "\n",
      "--->Documentation Code<---\n",
      "\n",
      "# AutomataAgent\n",
      "\n",
      "`AutomataAgent` is an autonomous agent designed to execute instructions and report the results back to the main system. It communicates with the OpenAI API to generate responses based on given instructions and manages interactions with various tools.\n",
      "\n",
      "## Overview\n",
      "\n",
      "An `AutomataAgent` instance takes a set of instructions and a configuration as input. The instructions are used to generate responses through interaction with the OpenAI API, while the configuration provides the necessary settings for the agent, such as API keys, model information, and more. The agent can execute a series of tasks, providing a final result or reporting an error if the result cannot be found in time. An agent can also be run further with new instructions, allowing users to submit follow-up instructions interactively.\n",
      "\n",
      "## Related Symbols\n",
      "\n",
      "- `automata.core.agent.agent_utils.generate_user_observation_message`\n",
      "- `automata.core.agent.database.AutomataAgentDatabase`\n",
      "- `automata.core.base.openai.OpenAIChatCompletionResult`\n",
      "- `automata.core.coordinator.AutomataCoordinator`\n",
      "- `automata.config.config_types.AutomataAgentConfig`\n",
      "- `config.AgentConfigName`\n",
      "\n",
      "## Example\n",
      "\n",
      "Creating an instance of `AutomataAgent` and executing instructions:\n",
      "\n",
      "```python\n",
      "from automata.core.agent.agent import AutomataAgent\n",
      "from automata.config.config_types import AutomataAgentConfig\n",
      "from automata.config.config_enums import AgentConfigName\n",
      "\n",
      "instructions = \"Find a solution for the given problem.\"\n",
      "config_name = AgentConfigName.AUTOMATA_MAIN\n",
      "config = AutomataAgentConfig.load(config_name)\n",
      "\n",
      "agent = AutomataAgent(instructions, config)\n",
      "agent.setup()\n",
      "result = agent.run()\n",
      "\n",
      "print(\"Result:\", result)\n",
      "```\n",
      "\n",
      "## Limitations\n",
      "\n",
      "`AutomataAgent` primarily relies on the OpenAI API for generating responses, which may be subject to API limitations, such as rate limits and the availability of models. Additionally, it requires a proper configuration for proper functioning, which may include setting up various tools and specifying valid API keys. The agent assumes a specific directory structure for configuration and tool files, which may limit customization.\n",
      "\n",
      "## Follow-up Questions:\n",
      "\n",
      "- Can `AutomataAgent` be made more flexible in terms of loading custom configurations and tool directories?\n",
      "- How can we handle OpenAI API limitations, such as rate limits, to ensure the smooth functioning of the agent?\n",
      "\n",
      "--->Vector<---\n",
      "\n",
      "[-0.04048205 -0.00826589  0.00743236 ... -0.01793491 -0.00899524\n",
      " -0.04223247]\n",
      "\n",
      "--->Symbol DotPath<---\n",
      "automata.core.coding.py_coding.writer.PyCodeWriter\n",
      "\n",
      "Integer Rank=2, Rank Score=0.004\n",
      "\n",
      "--->Documentation Code<---\n",
      "\n",
      "# PyCodeWriter\n",
      "\n",
      "`PyCodeWriter` is a utility class for writing Python code along Abstract Syntax Tree (AST) nodes. It provides functionality to create, delete, and update code for Python modules and operates on instances of `PyCodeRetriever` to work with Python code.\n",
      "\n",
      "## Overview\n",
      "\n",
      "`PyCodeWriter` allows you to modify code for modules, classes, and functions through methods like `create_new_module`, `delete_from_existing_module`, and `update_existing_module`. It also provides methods to manage newlines within the code, improving readability and organization. The class interacts with `PyCodeRetriever` to fetch the code for specific modules and navigate the syntax tree to make modifications.\n",
      "\n",
      "## Related Symbols\n",
      "\n",
      "- `automata.core.coding.py_coding.retriever.PyCodeRetriever`\n",
      "- `automata.core.coding.directory.DirectoryManager`\n",
      "- `automata.core.symbol.symbol_types.Symbol`\n",
      "- `automata.core.symbol.symbol_types.SymbolDocEmbedding`\n",
      "- `automata.core.agent.tools.py_code_writer.PyCodeWriterTool`\n",
      "\n",
      "## Example\n",
      "\n",
      "The following example demonstrates how to create an instance of `PyCodeWriter` and use it to create a new module and update an existing module.\n",
      "\n",
      "```python\n",
      "from automata.core.coding.py_coding.retriever import PyCodeRetriever\n",
      "from automata.core.coding.py_coding.writer import PyCodeWriter\n",
      "\n",
      "# Create an instance of PyCodeRetriever\n",
      "py_retriever = PyCodeRetriever()\n",
      "\n",
      "# Initialize the PyCodeWriter instance using the PyCodeRetriever\n",
      "py_writer = PyCodeWriter(py_retriever)\n",
      "\n",
      "# Create a new module with sample source code\n",
      "source_code = \"def hello_world():\\n    print('Hello, World!')\"\n",
      "module_dotpath = \"sample_module\"\n",
      "py_writer.create_new_module(module_dotpath, source_code, do_write=True)\n",
      "\n",
      "# Update an existing module with new source code\n",
      "source_code_update = \"def new_function():\\n    print('This is a new function.')\"\n",
      "disambiguator = \"hello_world\"\n",
      "py_writer.update_existing_module(module_dotpath, source_code_update, disambiguator, do_write=True)\n",
      "```\n",
      "\n",
      "## Limitations\n",
      "\n",
      "`PyCodeWriter` relies on the underlying `PyCodeRetriever` and `DirectoryManager` classes to fetch and modify code. If there are changes in the API or directory structure expected from these classes, it will affect the functionality of `PyCodeWriter`. Additionally, the class assumes that the input Python code follows specific coding styles and conventions; deviations from these assumptions might interfere with the code writing process.\n",
      "\n",
      "## Follow-up Questions:\n",
      "\n",
      "- How can PyCodeWriter handle custom coding styles and conventions?\n",
      "- Is there a way to extend this functionality for other languages besides Python?\n",
      "\n",
      "--->Vector<---\n",
      "\n",
      "[-1.28323967e-02  4.20126380e-05 -2.03359686e-03 ... -1.16578944e-03\n",
      "  4.80604963e-03 -5.25284857e-02]\n",
      "\n",
      "--->Symbol DotPath<---\n",
      "automata.core.symbol.graph.SymbolGraph\n",
      "\n",
      "Integer Rank=3, Rank Score=0.003\n",
      "\n",
      "--->Documentation Code<---\n",
      "\n",
      "# SymbolGraph\n",
      "\n",
      "`SymbolGraph` is a representation of symbols, their relationships, and dependency information. It is primarily used for exploring symbol dependencies, relationships, and available files in a given index file. The represented graph is a directed multigraph, which allows the use of different algorithms, especially those available in `networkx`, to optimize searches and traversals. It can also be used to build subgraphs with specific filtering criteria.\n",
      "\n",
      "## Overview\n",
      "\n",
      "`SymbolGraph` can be initialized with an index protobuf file and allows the user to explore the relationship between different symbols and their dependencies. It provides various methods to find relationships, callees, and callers of given symbols as well as the dependencies of a symbol. It can also be used to create a subgraph, which can be further processed or analyzed.\n",
      "\n",
      "## Related Symbols\n",
      "\n",
      "- `automata.core.symbol.symbol_types.Symbol`\n",
      "- `automata.core.symbol.symbol_types.SymbolReference`\n",
      "- `automata.core.symbol.symbol_types.SymbolFile`\n",
      "- `automata.core.symbol.symbol_types.SymbolDescriptor`\n",
      "- `automata.core.symbol.graph.GraphBuilder`\n",
      "- `automata.tests.unit.test_symbol_graph.test_build_real_graph_and_subgraph`\n",
      "- `automata.tests.unit.test_symbol_rank.test_get_ranks_small_graph`\n",
      "\n",
      "## Example\n",
      "\n",
      "The following is an example demonstrating how to create an instance of `SymbolGraph` using the path to an index protobuf file.\n",
      "\n",
      "```python\n",
      "from automata.core.symbol.graph import SymbolGraph\n",
      "\n",
      "index_path = \"/path/to/your/index/scip/file\"  # Replace with the path to your index protobuf file\n",
      "symbol_graph = SymbolGraph(index_path)\n",
      "```\n",
      "\n",
      "Once you have a `SymbolGraph` instance, you can explore the available symbols, files, and symbol relationships.\n",
      "\n",
      "```python\n",
      "all_symbols = symbol_graph.get_all_available_symbols()\n",
      "all_files = symbol_graph.get_all_files()\n",
      "```\n",
      "\n",
      "## Limitations\n",
      "\n",
      "`SymbolGraph` relies on index protobuf files, which can be large and slow to process. Furthermore, the class assumes a specific directory structure for index files and only accepts index protobuf files.\n",
      "\n",
      "## Follow-up Questions:\n",
      "\n",
      "- Are there alternative file formats for index files that could be more efficient for `SymbolGraph`?\n",
      "- Can `SymbolGraph` be further optimized to handle large index files more efficiently?\n",
      "\n",
      "--->Vector<---\n",
      "\n",
      "[-0.0286206  -0.01442049 -0.01623854 ... -0.03002546 -0.03209143\n",
      " -0.05988564]\n",
      "\n",
      "--->Symbol DotPath<---\n",
      "automata.core.database.vector.JSONVectorDatabase\n",
      "\n",
      "Integer Rank=4, Rank Score=0.003\n",
      "\n",
      "--->Documentation Code<---\n",
      "\n",
      "# JSONVectorDatabase\n",
      "\n",
      "`JSONVectorDatabase` is a concrete class for providing a vector database that saves and loads data in a JSON file. It serves as an implementation of a vector database provider, allowing adding, updating, and retrieving symbol embeddings, as well as calculating similarity between embeddings, and manipulating the database contents. The database stores symbol embeddings in a file specified by the user when instantiating the class.\n",
      "\n",
      "## Import Statements\n",
      "\n",
      "```python\n",
      "import jsonpickle\n",
      "from typing import Dict, List\n",
      "from automata.core.symbol.symbol_types import Symbol, SymbolEmbedding\n",
      "from automata.core.database.vector.VectorDatabaseProvider import VectorDatabaseProvider\n",
      "```\n",
      "\n",
      "## Related Symbols\n",
      "\n",
      "- `automata.core.database.provider.SymbolDatabaseProvider`\n",
      "- `automata.core.symbol.symbol_types.SymbolEmbedding`\n",
      "- `automata.core.symbol.symbol_types.Symbol`\n",
      "\n",
      "## Example\n",
      "\n",
      "The following code snippet demonstrates usage of `JSONVectorDatabase`:\n",
      "\n",
      "```python\n",
      "from automata.core.database.vector import JSONVectorDatabase\n",
      "from automata.core.symbol.symbol_types import Symbol, SymbolEmbedding\n",
      "\n",
      "# Create a JSONVectorDatabase with a specified file path\n",
      "file_path = \"my_database.json\"\n",
      "db = JSONVectorDatabase(file_path)\n",
      "\n",
      "# Add a symbol and its embedding to the database\n",
      "symbol = Symbol.from_string(\"example.symbol#\")\n",
      "embedding = SymbolEmbedding(symbol, \"embedding_source\", [1, 2, 3])\n",
      "db.add(embedding)\n",
      "\n",
      "# Check if the database contains the symbol\n",
      "assert db.contains(symbol)\n",
      "\n",
      "# Get the embedding for the symbol\n",
      "retrieved_embedding = db.get(symbol)\n",
      "assert retrieved_embedding == embedding\n",
      "\n",
      "# Update the embedding of the symbol\n",
      "new_embedding = SymbolEmbedding(symbol, \"new_embedding_source\", [4, 5, 6])\n",
      "db.update(new_embedding)\n",
      "\n",
      "# Save the database to the JSON file\n",
      "db.save()\n",
      "\n",
      "# Load the database from the JSON file\n",
      "db.load()\n",
      "\n",
      "# Discard the symbol from the database\n",
      "db.discard(symbol)\n",
      "\n",
      "# Clear the database\n",
      "db.clear()\n",
      "```\n",
      "\n",
      "## Limitations\n",
      "\n",
      "The `JSONVectorDatabase` class is an abstract base class, which means the `calculate_similarity()` method is currently not implemented, and needs to be implemented according to the specific similarity measure to be used when comparing embeddings. Additionally, the loading and saving of database assumes the JSON file content is encoded and decoded using the `jsonpickle` module, which might limit the compatibility of the JSON file with different libraries or applications.\n",
      "\n",
      "## Follow-up Questions:\n",
      "\n",
      "1. What similarity measure should be used and implemented in the `calculate_similarity()` method for comparing embeddings?\n",
      "2. How can we improve compatibility of the JSON file with different libraries or applications while maintaining the functionality of the class?\n",
      "\n",
      "--->Vector<---\n",
      "\n",
      "[-0.04066547 -0.02067527 -0.00353494 ... -0.00612791 -0.02614209\n",
      " -0.04721469]\n",
      "\n",
      "--->Symbol DotPath<---\n",
      "automata.core.base.tool.Tool\n",
      "\n",
      "Integer Rank=5, Rank Score=0.003\n",
      "\n",
      "--->Documentation Code<---\n",
      "\n",
      "# Tool\n",
      "\n",
      "`Tool` is a class that directly takes in a function or a coroutine for execution. It is built on top of the `BaseTool` class and provides an easier way to create a tool without the need to define a separate class for each tool.\n",
      "\n",
      "## Overview\n",
      "\n",
      "The `Tool` class is primarily used for creating instances of tools with a specific function or coroutine, which will be executed when the tool is called. This class allows users to quickly create tools without having to subclass `BaseTool` and define separate `_run` and `_arun` methods for each tool. It provides a convenient and concise way to create and manage tools by taking in a function or coroutine directly, along with a name and a description.\n",
      "\n",
      "## Related Symbols\n",
      "\n",
      "- `automata.core.base.base_tool.BaseTool`\n",
      "- `automata.tests.unit.test_tool.TestTool`\n",
      "- `automata.core.agent.agent_enums.ToolField`\n",
      "- `automata.tests.unit.test_tool.test_toolkit`\n",
      "\n",
      "## Example\n",
      "\n",
      "The following example demonstrates how to create an instance of `Tool` with a simple function:\n",
      "\n",
      "```python\n",
      "from typing import Callable\n",
      "from automata.core.base.tool import Tool\n",
      "\n",
      "def sample_function(text: str) -> str:\n",
      "    return f\"Processed: {text}\"\n",
      "\n",
      "tool = Tool(\n",
      "    name=\"SampleTool\",\n",
      "    func=sample_function,\n",
      "    description=\"A sample tool for demonstration purposes\",\n",
      ")\n",
      "\n",
      "response = tool((\"Hello, World!\",))\n",
      "print(response)  # Output: Processed: Hello, World!\n",
      "```\n",
      "\n",
      "## Limitations\n",
      "\n",
      "The `Tool` class is designed to simplify the creation of custom tools, but it may not be suitable for more complex use cases that require additional functionality beyond what is provided by the `BaseTool` class.\n",
      "\n",
      "If more advanced features are needed, consider subclassing `BaseTool` and implementing the required methods.\n",
      "\n",
      "## Follow-up Questions:\n",
      "\n",
      "- Does the `Tool` class inherit all methods and attributes from `BaseTool`?\n",
      "- If a method in `BaseTool` is marked as abstract, how does the `Tool` class handle this?\n",
      "\n",
      "--->Vector<---\n",
      "\n",
      "[-0.02425419 -0.02298216 -0.01152681 ...  0.02342523 -0.01903746\n",
      " -0.0420768 ]\n",
      "\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Symbol Symbol(scip-python python automata 9db05b7e7ebd49f93703df45accd7e5f9d5cedb0 posixpath/join()., scip-python, Package(python automata 9db05b7e7ebd49f93703df45accd7e5f9d5cedb0), (Descriptor(posixpath, 1), Descriptor(join, 4))) not in database'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPrinting out Documentation Embeddings for top ten ranked symbols\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ir, (symbol, rank) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(ranks[\u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m10\u001b[39m]):\n\u001b[0;32m---> 11\u001b[0m     symbol_doc_embedding \u001b[38;5;241m=\u001b[39m \u001b[43membedding_doc_db\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43msymbol\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--->Symbol DotPath<---\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msymbol\u001b[38;5;241m.\u001b[39mdotpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mInteger Rank=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Rank Score=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrank\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--->Documentation Code<---\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msymbol_doc_embedding\u001b[38;5;241m.\u001b[39membedding_source\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/_Automata_/automata/core/database/vector.py:130\u001b[0m, in \u001b[0;36mJSONVectorDatabase.get\u001b[0;34m(self, symbol)\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;124;03mGets the vector for the given symbol\u001b[39;00m\n\u001b[1;32m    122\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;124;03m    KeyError: If the symbol is not in the database\u001b[39;00m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m symbol\u001b[38;5;241m.\u001b[39mdotpath \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex:\n\u001b[0;32m--> 130\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSymbol \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msymbol\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in database\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex[symbol\u001b[38;5;241m.\u001b[39mdotpath]]\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Symbol Symbol(scip-python python automata 9db05b7e7ebd49f93703df45accd7e5f9d5cedb0 posixpath/join()., scip-python, Package(python automata 9db05b7e7ebd49f93703df45accd7e5f9d5cedb0), (Descriptor(posixpath, 1), Descriptor(join, 4))) not in database'"
     ]
    }
   ],
   "source": [
    "embedding_doc_fpath = os.path.join(\n",
    "    config_fpath(),\n",
    "    ConfigCategory.SYMBOL.value,\n",
    "    \"symbol_doc_embedding_l3.json\"\n",
    ")\n",
    "\n",
    "embedding_doc_db = JSONVectorDatabase(embedding_doc_fpath)\n",
    "\n",
    "print(\"Printing out Documentation Embeddings for top ten ranked symbols\\n\")\n",
    "for ir, (symbol, rank) in enumerate(ranks[0:10]):\n",
    "    symbol_doc_embedding = embedding_doc_db.get(symbol)\n",
    "    print(f\"--->Symbol DotPath<---\\n{symbol.dotpath}\\n\\nInteger Rank={ir}, Rank Score={rank:.3f}\\n\")\n",
    "    print(f\"--->Documentation Code<---\\n\\n{symbol_doc_embedding.embedding_source}\\n\")\n",
    "    print(f\"--->Vector<---\\n\\n{symbol_doc_embedding.vector}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
