{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "019bfa33",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO:automata.singletons.py_module_loader:Loading modules with root path: /Users/ocolegrove/automata_fresh_2/automata/core/../.. and py path: /Users/ocolegrove/automata_fresh_2/automata/core/../../automata\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "\n",
    "from automata.cli.commands import reconfigure_logging\n",
    "from automata.config.base import AgentConfigName\n",
    "from automata.config.openai_agent import OpenAIAutomataAgentConfigBuilder\n",
    "from automata.agent.providers import OpenAIAutomataAgent\n",
    "from automata.singletons.dependency_factory import dependency_factory\n",
    "from automata.singletons.py_module_loader import py_module_loader\n",
    "from automata.tools.factory import AgentToolFactory\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "reconfigure_logging(\"DEBUG\")\n",
    "\n",
    "py_module_loader.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9852e2c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO:automata.singletons.dependency_factory:Building dependencies for toolkit_list ['py-reader']...\u001b[0m\n",
      "\u001b[32mINFO:automata.singletons.dependency_factory:Building py_reader...\u001b[0m\n",
      "\u001b[32mINFO:automata.singletons.dependency_factory:Creating dependency py_reader\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Construct the set of all dependencies that will be used to build the tools\n",
    "toolkit_list = [\"py-reader\"]#\"context-oracle\"]\n",
    "tool_dependencies = dependency_factory.build_dependencies_for_tools(toolkit_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb0430f9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Build the tools\n",
    "tools = AgentToolFactory.build_tools(toolkit_list, **tool_dependencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e5b36ce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO:automata.singletons.dependency_factory:Creating dependency symbol_rank\u001b[0m\n",
      "\u001b[32mINFO:automata.singletons.dependency_factory:Creating dependency subgraph\u001b[0m\n",
      "\u001b[32mINFO:automata.singletons.dependency_factory:Creating dependency symbol_graph\u001b[0m\n",
      "\u001b[32mINFO:automata.symbol.graph.navigator:Pre-computing bounding boxes for all rankable symbols\u001b[0m\n",
      "Error computing bounding box for scip-python python automata 264a4fd97ce6a05c5972ef61db63b0f3802b766f `automata.code_parsers.py.ast_utils`/BoundingBox#: Module automata.code_parsers.py.ast_utils not found\n",
      "Error computing bounding box for scip-python python automata 264a4fd97ce6a05c5972ef61db63b0f3802b766f `automata.code_parsers.py.ast_utils`/DocstringRemover#: Module automata.code_parsers.py.ast_utils not found\n",
      "Error computing bounding box for scip-python python automata 264a4fd97ce6a05c5972ef61db63b0f3802b766f `automata.code_parsers.py.ast_utils`/DocstringRemover#visit().: Module automata.code_parsers.py.ast_utils not found\n",
      "Error computing bounding box for scip-python python automata 264a4fd97ce6a05c5972ef61db63b0f3802b766f `automata.code_parsers.py.ast_utils`/ImportRemover#: Module automata.code_parsers.py.ast_utils not found\n",
      "Error computing bounding box for scip-python python automata 264a4fd97ce6a05c5972ef61db63b0f3802b766f `automata.code_parsers.py.ast_utils`/ImportRemover#visit().: Module automata.code_parsers.py.ast_utils not found\n",
      "Error computing bounding box for scip-python python automata 264a4fd97ce6a05c5972ef61db63b0f3802b766f `automata.code_parsers.py.ast_utils`/LineItem#: Module automata.code_parsers.py.ast_utils not found\n",
      "Error computing bounding box for scip-python python automata 264a4fd97ce6a05c5972ef61db63b0f3802b766f `automata.code_parsers.py.ast_utils`/fetch_bounding_box().: Module automata.code_parsers.py.ast_utils not found\n",
      "Error computing bounding box for scip-python python automata 264a4fd97ce6a05c5972ef61db63b0f3802b766f `automata.code_parsers.py.ast_utils`/get_docstring_from_node().: Module automata.code_parsers.py.ast_utils not found\n",
      "Error computing bounding box for scip-python python automata 264a4fd97ce6a05c5972ef61db63b0f3802b766f `automata.code_parsers.py.ast_utils`/get_node_without_docstrings().: Module automata.code_parsers.py.ast_utils not found\n",
      "Error computing bounding box for scip-python python automata 264a4fd97ce6a05c5972ef61db63b0f3802b766f `automata.code_parsers.py.ast_utils`/get_node_without_imports().: Module automata.code_parsers.py.ast_utils not found\n",
      "Error computing bounding box for scip-python python automata 264a4fd97ce6a05c5972ef61db63b0f3802b766f `automata.code_parsers.py.doc_writer`/PyDocWriter#: Module automata.code_parsers.py.doc_writer not found\n",
      "Error computing bounding box for scip-python python automata 264a4fd97ce6a05c5972ef61db63b0f3802b766f `automata.code_parsers.py.doc_writer`/PyDocWriter#__init__().: Module automata.code_parsers.py.doc_writer not found\n",
      "Error computing bounding box for scip-python python automata 264a4fd97ce6a05c5972ef61db63b0f3802b766f `automata.code_parsers.py.doc_writer`/PyDocWriter#camel_to_snake().: Module automata.code_parsers.py.doc_writer not found\n",
      "Error computing bounding box for scip-python python automata 264a4fd97ce6a05c5972ef61db63b0f3802b766f `automata.code_parsers.py.doc_writer`/PyDocWriter#check_camel_case().: Module automata.code_parsers.py.doc_writer not found\n",
      "Error computing bounding box for scip-python python automata 264a4fd97ce6a05c5972ef61db63b0f3802b766f `automata.code_parsers.py.doc_writer`/PyDocWriter#generate_index_files().: Module automata.code_parsers.py.doc_writer not found\n",
      "Error computing bounding box for scip-python python automata 264a4fd97ce6a05c5972ef61db63b0f3802b766f `automata.code_parsers.py.doc_writer`/PyDocWriter#generate_module_summary().: Module automata.code_parsers.py.doc_writer not found\n",
      "Error computing bounding box for scip-python python automata 264a4fd97ce6a05c5972ef61db63b0f3802b766f `automata.code_parsers.py.doc_writer`/PyDocWriter#generate_rst_files().: Module automata.code_parsers.py.doc_writer not found\n",
      "Error computing bounding box for scip-python python automata 264a4fd97ce6a05c5972ef61db63b0f3802b766f `automata.code_parsers.py.doc_writer`/PyDocWriter#get_payload().: Module automata.code_parsers.py.doc_writer not found\n",
      "Error computing bounding box for scip-python python automata 264a4fd97ce6a05c5972ef61db63b0f3802b766f `automata.code_parsers.py.doc_writer`/PyDocWriter#generate_summary().: Module automata.code_parsers.py.doc_writer not found\n",
      "Error computing bounding box for scip-python python automata 264a4fd97ce6a05c5972ef61db63b0f3802b766f `automata.code_parsers.py.doc_writer`/PyDocWriter#write_documentation().: Module automata.code_parsers.py.doc_writer not found\n",
      "Error computing bounding box for scip-python python automata 264a4fd97ce6a05c5972ef61db63b0f3802b766f `automata.config.openai_agent`/OpenAIAutomataAgentConfig#Config#: Symbol scip-python python automata 264a4fd97ce6a05c5972ef61db63b0f3802b766f `automata.config.openai_agent`/OpenAIAutomataAgentConfig#Config# not found\n",
      "Error computing bounding box for scip-python python automata 264a4fd97ce6a05c5972ef61db63b0f3802b766f `automata.llm.providers.openai`/OpenAIChatCompletionProvider#get_approximate_tokens_consumed().: Symbol scip-python python automata 264a4fd97ce6a05c5972ef61db63b0f3802b766f `automata.llm.providers.openai`/OpenAIChatCompletionProvider#get_approximate_tokens_consumed(). not found\n",
      "\u001b[32mINFO:automata.symbol.graph.navigator:Finished pre-computing bounding boxes for all rankable symbols in 1.1399641036987305 seconds\u001b[0m\n",
      "\u001b[32mINFO:automata.symbol.graph.symbol_graph:Building the rankable symbol subgraph...\u001b[0m\n",
      " 11%|███████████████████████▉                                                                                                                                                                                          | 79/692 [00:02<00:19, 31.68it/s]\u001b[31mERROR:automata.symbol.graph.symbol_graph:Error processing scip-python python automata 264a4fd97ce6a05c5972ef61db63b0f3802b766f `automata.code_parsers.py.ast_utils`/BoundingBox#: Symbol(scip-python python automata 264a4fd97ce6a05c5972ef61db63b0f3802b766f `automata.code_parsers.py.ast_utils`/BoundingBox#, scip-python, Package(python automata 264a4fd97ce6a05c5972ef61db63b0f3802b766f), (Descriptor(automata.code_parsers.py.ast_utils, 1), Descriptor(BoundingBox, 2)))\u001b[0m\n",
      "\u001b[31mERROR:automata.symbol.graph.symbol_graph:Error processing scip-python python automata 264a4fd97ce6a05c5972ef61db63b0f3802b766f `automata.code_parsers.py.ast_utils`/DocstringRemover#: Symbol(scip-python python automata 264a4fd97ce6a05c5972ef61db63b0f3802b766f `automata.code_parsers.py.ast_utils`/DocstringRemover#, scip-python, Package(python automata 264a4fd97ce6a05c5972ef61db63b0f3802b766f), (Descriptor(automata.code_parsers.py.ast_utils, 1), Descriptor(DocstringRemover, 2)))\u001b[0m\n",
      "\u001b[31mERROR:automata.symbol.graph.symbol_graph:Error processing scip-python python automata 264a4fd97ce6a05c5972ef61db63b0f3802b766f `automata.code_parsers.py.ast_utils`/DocstringRemover#visit().: Symbol(scip-python python automata 264a4fd97ce6a05c5972ef61db63b0f3802b766f `automata.code_parsers.py.ast_utils`/DocstringRemover#visit()., scip-python, Package(python automata 264a4fd97ce6a05c5972ef61db63b0f3802b766f), (Descriptor(automata.code_parsers.py.ast_utils, 1), Descriptor(DocstringRemover, 2), Descriptor(visit, 4)))\u001b[0m\n",
      "\u001b[31mERROR:automata.symbol.graph.symbol_graph:Error processing scip-python python automata 264a4fd97ce6a05c5972ef61db63b0f3802b766f `automata.code_parsers.py.ast_utils`/ImportRemover#: Symbol(scip-python python automata 264a4fd97ce6a05c5972ef61db63b0f3802b766f `automata.code_parsers.py.ast_utils`/ImportRemover#, scip-python, Package(python automata 264a4fd97ce6a05c5972ef61db63b0f3802b766f), (Descriptor(automata.code_parsers.py.ast_utils, 1), Descriptor(ImportRemover, 2)))\u001b[0m\n",
      "\u001b[31mERROR:automata.symbol.graph.symbol_graph:Error processing scip-python python automata 264a4fd97ce6a05c5972ef61db63b0f3802b766f `automata.code_parsers.py.ast_utils`/ImportRemover#visit().: Symbol(scip-python python automata 264a4fd97ce6a05c5972ef61db63b0f3802b766f `automata.code_parsers.py.ast_utils`/ImportRemover#visit()., scip-python, Package(python automata 264a4fd97ce6a05c5972ef61db63b0f3802b766f), (Descriptor(automata.code_parsers.py.ast_utils, 1), Descriptor(ImportRemover, 2), Descriptor(visit, 4)))\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR:automata.symbol.graph.symbol_graph:Error processing scip-python python automata 264a4fd97ce6a05c5972ef61db63b0f3802b766f `automata.code_parsers.py.ast_utils`/LineItem#: Symbol(scip-python python automata 264a4fd97ce6a05c5972ef61db63b0f3802b766f `automata.code_parsers.py.ast_utils`/LineItem#, scip-python, Package(python automata 264a4fd97ce6a05c5972ef61db63b0f3802b766f), (Descriptor(automata.code_parsers.py.ast_utils, 1), Descriptor(LineItem, 2)))\u001b[0m\n",
      "\u001b[31mERROR:automata.symbol.graph.symbol_graph:Error processing scip-python python automata 264a4fd97ce6a05c5972ef61db63b0f3802b766f `automata.code_parsers.py.ast_utils`/fetch_bounding_box().: Symbol(scip-python python automata 264a4fd97ce6a05c5972ef61db63b0f3802b766f `automata.code_parsers.py.ast_utils`/fetch_bounding_box()., scip-python, Package(python automata 264a4fd97ce6a05c5972ef61db63b0f3802b766f), (Descriptor(automata.code_parsers.py.ast_utils, 1), Descriptor(fetch_bounding_box, 4)))\u001b[0m\n",
      "\u001b[31mERROR:automata.symbol.graph.symbol_graph:Error processing scip-python python automata 264a4fd97ce6a05c5972ef61db63b0f3802b766f `automata.code_parsers.py.ast_utils`/get_docstring_from_node().: Symbol(scip-python python automata 264a4fd97ce6a05c5972ef61db63b0f3802b766f `automata.code_parsers.py.ast_utils`/get_docstring_from_node()., scip-python, Package(python automata 264a4fd97ce6a05c5972ef61db63b0f3802b766f), (Descriptor(automata.code_parsers.py.ast_utils, 1), Descriptor(get_docstring_from_node, 4)))\u001b[0m\n",
      "\u001b[31mERROR:automata.symbol.graph.symbol_graph:Error processing scip-python python automata 264a4fd97ce6a05c5972ef61db63b0f3802b766f `automata.code_parsers.py.ast_utils`/get_node_without_docstrings().: Symbol(scip-python python automata 264a4fd97ce6a05c5972ef61db63b0f3802b766f `automata.code_parsers.py.ast_utils`/get_node_without_docstrings()., scip-python, Package(python automata 264a4fd97ce6a05c5972ef61db63b0f3802b766f), (Descriptor(automata.code_parsers.py.ast_utils, 1), Descriptor(get_node_without_docstrings, 4)))\u001b[0m\n",
      "\u001b[31mERROR:automata.symbol.graph.symbol_graph:Error processing scip-python python automata 264a4fd97ce6a05c5972ef61db63b0f3802b766f `automata.code_parsers.py.ast_utils`/get_node_without_imports().: Symbol(scip-python python automata 264a4fd97ce6a05c5972ef61db63b0f3802b766f `automata.code_parsers.py.ast_utils`/get_node_without_imports()., scip-python, Package(python automata 264a4fd97ce6a05c5972ef61db63b0f3802b766f), (Descriptor(automata.code_parsers.py.ast_utils, 1), Descriptor(get_node_without_imports, 4)))\u001b[0m\n",
      " 17%|███████████████████████████████████▉                                                                                                                                                                             | 119/692 [00:03<00:24, 23.55it/s]\u001b[31mERROR:automata.symbol.graph.symbol_graph:Error processing scip-python python automata 264a4fd97ce6a05c5972ef61db63b0f3802b766f `automata.code_parsers.py.doc_writer`/PyDocWriter#: Symbol(scip-python python automata 264a4fd97ce6a05c5972ef61db63b0f3802b766f `automata.code_parsers.py.doc_writer`/PyDocWriter#, scip-python, Package(python automata 264a4fd97ce6a05c5972ef61db63b0f3802b766f), (Descriptor(automata.code_parsers.py.doc_writer, 1), Descriptor(PyDocWriter, 2)))\u001b[0m\n",
      "\u001b[31mERROR:automata.symbol.graph.symbol_graph:Error processing scip-python python automata 264a4fd97ce6a05c5972ef61db63b0f3802b766f `automata.code_parsers.py.doc_writer`/PyDocWriter#__init__().: Symbol(scip-python python automata 264a4fd97ce6a05c5972ef61db63b0f3802b766f `automata.code_parsers.py.doc_writer`/PyDocWriter#__init__()., scip-python, Package(python automata 264a4fd97ce6a05c5972ef61db63b0f3802b766f), (Descriptor(automata.code_parsers.py.doc_writer, 1), Descriptor(PyDocWriter, 2), Descriptor(__init__, 4)))\u001b[0m\n",
      "\u001b[31mERROR:automata.symbol.graph.symbol_graph:Error processing scip-python python automata 264a4fd97ce6a05c5972ef61db63b0f3802b766f `automata.code_parsers.py.doc_writer`/PyDocWriter#camel_to_snake().: Symbol(scip-python python automata 264a4fd97ce6a05c5972ef61db63b0f3802b766f `automata.code_parsers.py.doc_writer`/PyDocWriter#camel_to_snake()., scip-python, Package(python automata 264a4fd97ce6a05c5972ef61db63b0f3802b766f), (Descriptor(automata.code_parsers.py.doc_writer, 1), Descriptor(PyDocWriter, 2), Descriptor(camel_to_snake, 4)))\u001b[0m\n",
      "\u001b[31mERROR:automata.symbol.graph.symbol_graph:Error processing scip-python python automata 264a4fd97ce6a05c5972ef61db63b0f3802b766f `automata.code_parsers.py.doc_writer`/PyDocWriter#check_camel_case().: Symbol(scip-python python automata 264a4fd97ce6a05c5972ef61db63b0f3802b766f `automata.code_parsers.py.doc_writer`/PyDocWriter#check_camel_case()., scip-python, Package(python automata 264a4fd97ce6a05c5972ef61db63b0f3802b766f), (Descriptor(automata.code_parsers.py.doc_writer, 1), Descriptor(PyDocWriter, 2), Descriptor(check_camel_case, 4)))\u001b[0m\n",
      "\u001b[31mERROR:automata.symbol.graph.symbol_graph:Error processing scip-python python automata 264a4fd97ce6a05c5972ef61db63b0f3802b766f `automata.code_parsers.py.doc_writer`/PyDocWriter#generate_index_files().: Symbol(scip-python python automata 264a4fd97ce6a05c5972ef61db63b0f3802b766f `automata.code_parsers.py.doc_writer`/PyDocWriter#generate_index_files()., scip-python, Package(python automata 264a4fd97ce6a05c5972ef61db63b0f3802b766f), (Descriptor(automata.code_parsers.py.doc_writer, 1), Descriptor(PyDocWriter, 2), Descriptor(generate_index_files, 4)))\u001b[0m\n",
      "\u001b[31mERROR:automata.symbol.graph.symbol_graph:Error processing scip-python python automata 264a4fd97ce6a05c5972ef61db63b0f3802b766f `automata.code_parsers.py.doc_writer`/PyDocWriter#generate_module_summary().: Symbol(scip-python python automata 264a4fd97ce6a05c5972ef61db63b0f3802b766f `automata.code_parsers.py.doc_writer`/PyDocWriter#generate_module_summary()., scip-python, Package(python automata 264a4fd97ce6a05c5972ef61db63b0f3802b766f), (Descriptor(automata.code_parsers.py.doc_writer, 1), Descriptor(PyDocWriter, 2), Descriptor(generate_module_summary, 4)))\u001b[0m\n",
      "\u001b[31mERROR:automata.symbol.graph.symbol_graph:Error processing scip-python python automata 264a4fd97ce6a05c5972ef61db63b0f3802b766f `automata.code_parsers.py.doc_writer`/PyDocWriter#generate_rst_files().: Symbol(scip-python python automata 264a4fd97ce6a05c5972ef61db63b0f3802b766f `automata.code_parsers.py.doc_writer`/PyDocWriter#generate_rst_files()., scip-python, Package(python automata 264a4fd97ce6a05c5972ef61db63b0f3802b766f), (Descriptor(automata.code_parsers.py.doc_writer, 1), Descriptor(PyDocWriter, 2), Descriptor(generate_rst_files, 4)))\u001b[0m\n",
      "\u001b[31mERROR:automata.symbol.graph.symbol_graph:Error processing scip-python python automata 264a4fd97ce6a05c5972ef61db63b0f3802b766f `automata.code_parsers.py.doc_writer`/PyDocWriter#generate_summary().: Symbol(scip-python python automata 264a4fd97ce6a05c5972ef61db63b0f3802b766f `automata.code_parsers.py.doc_writer`/PyDocWriter#generate_summary()., scip-python, Package(python automata 264a4fd97ce6a05c5972ef61db63b0f3802b766f), (Descriptor(automata.code_parsers.py.doc_writer, 1), Descriptor(PyDocWriter, 2), Descriptor(generate_summary, 4)))\u001b[0m\n",
      "\u001b[31mERROR:automata.symbol.graph.symbol_graph:Error processing scip-python python automata 264a4fd97ce6a05c5972ef61db63b0f3802b766f `automata.code_parsers.py.doc_writer`/PyDocWriter#get_payload().: Symbol(scip-python python automata 264a4fd97ce6a05c5972ef61db63b0f3802b766f `automata.code_parsers.py.doc_writer`/PyDocWriter#get_payload()., scip-python, Package(python automata 264a4fd97ce6a05c5972ef61db63b0f3802b766f), (Descriptor(automata.code_parsers.py.doc_writer, 1), Descriptor(PyDocWriter, 2), Descriptor(get_payload, 4)))\u001b[0m\n",
      "\u001b[31mERROR:automata.symbol.graph.symbol_graph:Error processing scip-python python automata 264a4fd97ce6a05c5972ef61db63b0f3802b766f `automata.code_parsers.py.doc_writer`/PyDocWriter#write_documentation().: Symbol(scip-python python automata 264a4fd97ce6a05c5972ef61db63b0f3802b766f `automata.code_parsers.py.doc_writer`/PyDocWriter#write_documentation()., scip-python, Package(python automata 264a4fd97ce6a05c5972ef61db63b0f3802b766f), (Descriptor(automata.code_parsers.py.doc_writer, 1), Descriptor(PyDocWriter, 2), Descriptor(write_documentation, 4)))\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|███████████████████████████████████████████████████                                                                                                                                                              | 169/692 [00:04<00:10, 49.73it/s]\u001b[31mERROR:automata.symbol.graph.symbol_graph:Error processing scip-python python automata 264a4fd97ce6a05c5972ef61db63b0f3802b766f `automata.config.openai_agent`/OpenAIAutomataAgentConfig#Config#: Symbol(scip-python python automata 264a4fd97ce6a05c5972ef61db63b0f3802b766f `automata.config.openai_agent`/OpenAIAutomataAgentConfig#Config#, scip-python, Package(python automata 264a4fd97ce6a05c5972ef61db63b0f3802b766f), (Descriptor(automata.config.openai_agent, 1), Descriptor(OpenAIAutomataAgentConfig, 2), Descriptor(Config, 2)))\u001b[0m\n",
      " 50%|█████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                                       | 349/692 [00:09<00:07, 46.07it/s]\u001b[31mERROR:automata.symbol.graph.symbol_graph:Error processing scip-python python automata 264a4fd97ce6a05c5972ef61db63b0f3802b766f `automata.llm.providers.openai`/OpenAIChatCompletionProvider#get_approximate_tokens_consumed().: Symbol(scip-python python automata 264a4fd97ce6a05c5972ef61db63b0f3802b766f `automata.llm.providers.openai`/OpenAIChatCompletionProvider#get_approximate_tokens_consumed()., scip-python, Package(python automata 264a4fd97ce6a05c5972ef61db63b0f3802b766f), (Descriptor(automata.llm.providers.openai, 1), Descriptor(OpenAIChatCompletionProvider, 2), Descriptor(get_approximate_tokens_consumed, 4)))\u001b[0m\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 692/692 [00:23<00:00, 29.36it/s]\n",
      "\u001b[32mINFO:automata.symbol.graph.symbol_graph:Built the rankable symbol subgraph\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Build the agent config\n",
    "config_name = AgentConfigName(\"automata-main\")\n",
    "\n",
    "agent_config = (\n",
    "    OpenAIAutomataAgentConfigBuilder.from_name(config_name)\n",
    "    .with_tools(tools)\n",
    "    .with_model(\"gpt-4\")\n",
    "    .with_max_iterations(2)\n",
    "    .build()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38086fcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('automata.core.base.database.vector.VectorDatabaseProvider',\n",
       "  0.004384584761099946),\n",
       " ('automata.core.base.database.vector.ChromaVectorDatabase',\n",
       "  0.0035106956754573904),\n",
       " ('automata.singletons.github_client.GitHubClient', 0.0034109238995391326),\n",
       " ('automata.core.base.database.relational.RelationalDatabase',\n",
       "  0.002929687500000001),\n",
       " ('automata.llm.providers.openai.OpenAIChatCompletionProvider',\n",
       "  0.0027474632488570403),\n",
       " ('automata.symbol_embedding.vector_databases.ChromaSymbolEmbeddingVectorDatabase',\n",
       "  0.002706981262515736),\n",
       " ('automata.singletons.dependency_factory.DependencyFactory',\n",
       "  0.002540298289368039),\n",
       " ('automata.singletons.github_client.RepositoryClient', 0.0024926875272844417),\n",
       " ('automata.llm.providers.openai.OpenAIFunction', 0.002467728584346458),\n",
       " ('automata.core.base.database.vector.JSONVectorDatabase',\n",
       "  0.00240284748673057)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "symbol_rank = dependency_factory.get(\"symbol_rank\")\n",
    "symbol_rank.get_top_symbols(\n",
    "                10\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "43954b29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'class VectorDatabaseProvider(abc.ABC, Generic[K, V]):\\n    \"\"\"An abstract base class for different types of vector database providers.\"\"\"\\n\\n    @abc.abstractmethod\\n    def __len__(self) -> int:\\n        pass\\n\\n    @abc.abstractmethod\\n    def save(self) -> None:\\n        \"\"\"Abstract method to save data.\"\"\"\\n        pass\\n\\n    @abc.abstractmethod\\n    def load(self) -> None:\\n        \"\"\"Abstract method to load data.\"\"\"\\n        pass\\n\\n    @abc.abstractmethod\\n    def clear(self) -> None:\\n        \"\"\"Abstract method to clear all entries.\"\"\"\\n        pass\\n\\n    @abc.abstractmethod\\n    def get_ordered_keys(self) -> List[K]:\\n        \"\"\"Abstract method to get all keys stored in the database.\"\"\"\\n        pass\\n\\n    @abc.abstractmethod\\n    def get_ordered_embeddings(self) -> List[V]:\\n        \"\"\"\\n        Abstract method to get an ordered list entries in the database.\\n        These vectors should be ordered in the same way as the keys returned by get_ordered_keys.\\n        \"\"\"\\n        pass\\n\\n    @abc.abstractmethod\\n    def add(self, entry: V) -> None:\\n        \"\"\"Abstract method to add an entry to the database.\"\"\"\\n        pass\\n\\n    @abc.abstractmethod\\n    def batch_add(self, entries: V) -> None:\\n        \"\"\"Abstract method to add a batch of specific entries to the database.\"\"\"\\n        pass\\n\\n    @abc.abstractmethod\\n    def update_entry(self, entry: V) -> None:\\n        \"\"\"Abstract method to update a specific entry.\"\"\"\\n        pass\\n\\n    @abc.abstractmethod\\n    def batch_update(self, entries: List[V]) -> None:\\n        \"\"\"Abstract method to update a list of specific entries.\"\"\"\\n        pass\\n\\n    @abc.abstractmethod\\n    def entry_to_key(self, entry: V) -> K:\\n        \"\"\"Abstract method to generate a unique hashable key from an entry of type V.\"\"\"\\n        pass\\n\\n    @abc.abstractmethod\\n    def contains(self, key: K) -> bool:\\n        \"\"\"Abstract method to check if a specific entry is present in the database.\"\"\"\\n        pass\\n\\n    @abc.abstractmethod\\n    def get(self, key: K) -> V:\\n        \"\"\"Abstract method to get a specific entry.\"\"\"\\n        pass\\n\\n    @abc.abstractmethod\\n    def batch_get(self, keys: List[K]) -> List[V]:\\n        \"\"\"Abstract method to get a batch of specific entries.\"\"\"\\n        pass\\n\\n    @abc.abstractmethod\\n    def discard(self, key: K) -> None:\\n        \"\"\"Abstract method to discard a specific entry.\"\"\"\\n        pass\\n\\n    @abc.abstractmethod\\n    def batch_discard(self, keys: List[K]) -> None:\\n        \"\"\"Abstract method to discard a batch of specific entries.\"\"\"\\n        pass'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from automata.code_parsers.py import PyReader\n",
    "py_reader = PyReader()\n",
    "py_reader.get_source_code(\"automata.core.base.database.vector\", \"VectorDatabaseProvider\")#\"core.base.database.vector.\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "67aa2161",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36mDEBUG:automata.agent.providers:Setting up agent with tools = [OpenAITool(function=<bound method PyReaderToolkitBuilder._run_indexer_retrieve_code of <automata.tools.builders.py_reader.PyReaderOpenAIToolkit object at 0x10f28a610>>, name='py-retriever-retrieve-raw-code', description='Returns the code of the python package, module, standalone function, class, or method at the given module path and sub-module (e.g. node) path. If no match is found, then \"No Result Found.\" is returned.\\n\\nFor example - suppose we want the entire source code of a module located in \"target_module.py\" of the root directory,then the correct tool input is:\\narguments: {\"module_path\": \"target_module\"}Suppose instead the file is located in a subdirectory called module_directory:\\narguments: {\"module_path\": \"module_directory.target_module\"}Next, suppose that we just want to retrieve \\'target_function\\' in target_module:arguments: {\"module_path\": \"module_directory.target_module\", \"node_path\": \"target_function\"}Lastly, if the function is defined in a class, TargetClass, then the correct tool input is:\\narguments: {\"module_path\": \"module_directory.target_module\", \"node_path\": \"TargetClass.target_function\"}', coroutine=None, properties={'module_path': {'type': 'string', 'description': 'The path to the module to retrieve code from.'}, 'node_path': {'type': 'string', 'description': 'The path to the object to retrieve code from.'}}, required=['module_path'], openai_function=<automata.llm.providers.openai.OpenAIFunction object at 0x10f28a250>), OpenAITool(function=<bound method PyReaderToolkitBuilder._run_indexer_retrieve_docstring of <automata.tools.builders.py_reader.PyReaderOpenAIToolkit object at 0x10f28a610>>, name='py-retriever-retrieve-docstring', description='Identical to py-retriever-retrieve-code, except returns the docstring instead of raw code.', coroutine=None, properties={'module_path': {'type': 'string', 'description': 'The path to the module to retrieve code from.'}, 'node_path': {'type': 'string', 'description': 'The path to the object to retrieve code from.'}}, required=['module_path'], openai_function=<automata.llm.providers.openai.OpenAIFunction object at 0x10f289b10>)]\u001b[0m\n",
      "\u001b[36mDEBUG:automata.agent.providers:Adding the following initial mesasge to the conversation assistant:\n",
      "content=Hello, I am Automata, OpenAI's most skilled coding system. How may I assist you today?\n",
      "function_call=None\u001b[0m\n",
      "\u001b[36mDEBUG:root:\n",
      "------------------------------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[36mDEBUG:automata.agent.providers:Adding the following initial mesasge to the conversation user:\n",
      "content=Please carry out the following instruction retrieve the source code for the VectorDatabaseProvider\n",
      "function_call=None\u001b[0m\n",
      "\u001b[36mDEBUG:root:\n",
      "------------------------------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[36mDEBUG:automata.agent.providers:Adding the following initial mesasge to the conversation assistant:\n",
      "content=None\n",
      "function_call=FunctionCall(name='initializer', arguments='{}')\u001b[0m\n",
      "\u001b[36mDEBUG:root:\n",
      "------------------------------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[36mDEBUG:automata.agent.providers:Adding the following initial mesasge to the conversation user:\n",
      "content=Continue...\n",
      "function_call=None\u001b[0m\n",
      "\u001b[36mDEBUG:root:\n",
      "------------------------------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[36mDEBUG:automata.agent.providers:Initializing with System Instruction -- \n",
      "\n",
      "You are Automata Master, an advanced autonomous software architect developed by OpenAI.  You are designed to specifically operate within local Python repositories.  With your capability to understand and process natural language instructions,  you perform tasks efficiently using your available functions. \n",
      "When you have completed your task, return the final result to the user as soon as possible via the `call_termination` function.\n",
      "\n",
      "Persistently execute multiple actions until you have amassed enough information to ensure an high likelihood of successfully completing the given task.\n",
      "IMPORTANT - Note that you have a maxiumum of 2 iterations to complete the task, after which point the session terminates. If you are approaching the limit, then promptly return a result.\n",
      "An example of the Thoughts->Function Call --> Observations --> Thoughts->Function Call --> ... chain follows below.\n",
      "\n",
      "**Example pattern**\n",
      "\n",
      "  *Assistant*\n",
      "    Hello, I am Automata, OpenAI's most skilled coding system. How may I assist you today?\n",
      "\n",
      "  *User*\n",
      "    Please carry out the following instruction Determine how to best use Automata.\n",
      "\n",
      "  *Assistant*\n",
      "    function_call:\n",
      "    {\n",
      "      'name: \"context_oracle\"\n",
      "      'arguments': '{\"query\": \"Automata\"}'\n",
      "    }\n",
      "\n",
      "  *User*\n",
      "    Execution Result:\n",
      "\n",
      "    ...RESULT CONTINUES...\n",
      "\n",
      "  *Assistant*\n",
      "    content:\n",
      "      Let us first analyze ...THOUGHT CONTINUES...\n",
      "\n",
      "  ...CONVERSATION CONTINUES...\n",
      "  \n",
      "  *Assistant*\n",
      "    function_call:\n",
      "    {\n",
      "      'name': 'call_termination', \n",
      "      'arguments': '{\"result\": \"```python\\nclass  SymbolDocEmbeddingHandler(SymbolEmbeddingHandler): ...CODE CONTINUES...```\"}'\n",
      "    }\n",
      "\n",
      "\n",
      "An overview of the most important python modules, and their internal functions and classes is given immediately below to help you in this task.\n",
      "\n",
      "automata.core.base.database.vector.VectorDatabaseProvider\n",
      "automata.core.base.database.vector.ChromaVectorDatabase\n",
      "automata.singletons.github_client.GitHubClient\n",
      "automata.core.base.database.relational.RelationalDatabase\n",
      "automata.llm.providers.openai.OpenAIChatCompletionProvider\n",
      "automata.symbol_embedding.vector_databases.ChromaSymbolEmbeddingVectorDatabase\n",
      "automata.singletons.dependency_factory.DependencyFactory\n",
      "automata.singletons.github_client.RepositoryClient\n",
      "automata.llm.providers.openai.OpenAIFunction\n",
      "automata.core.base.database.vector.JSONVectorDatabase\n",
      "automata.config.base.AgentConfigBuilder\n",
      "automata.agent.providers.OpenAIAutomataAgent\n",
      "automata.experimental.search.symbol_search.SymbolSearch\n",
      "automata.symbol.graph.navigator.SymbolGraphNavigator\n",
      "automata.llm.providers.openai.OpenAIChatCompletionProvider._stream_message\n",
      "automata.tasks.base.Task\n",
      "automata.symbol.graph.symbol_graph.SymbolGraph\n",
      "automata.symbol_embedding.builders.SymbolDocEmbeddingBuilder\n",
      "automata.experimental.search.rank.SymbolRank\n",
      "automata.tasks.environment.AutomataTaskEnvironment\n",
      "automata.config.base.AgentConfig\n",
      "automata.singletons.py_module_loader.PyModuleLoader\n",
      "automata.symbol.base.Symbol\n",
      "automata.llm.foundation.LLMConversation\n",
      "automata.symbol.parser._SymbolParser\n",
      "automata.code_parsers.py.dotpath_map.DotPathMap\n",
      "automata.tools.builders.symbol_search.SymbolSearchToolkitBuilder\n",
      "automata.symbol_embedding.handler.SymbolEmbeddingHandler\n",
      "automata.core.base.database.relational.SQLDatabase\n",
      "automata.agent.agent.Agent\n",
      "4\n",
      "automata.embedding.base.EmbeddingBuilder\n",
      "6\n",
      "0\n",
      "automata.code_parsers.py.context_processing.context_retriever.InterfaceContextComponent\n",
      "5\n",
      "9\n",
      "8\n",
      "automata.symbol.graph.graph_builder.GraphBuilder\n",
      "automata.embedding.base.EmbeddingSimilarityCalculator\n",
      "automata.agent.agent.AgentInstance\n",
      "automata.symbol.base.SymbolDescriptor\n",
      "automata.llm.foundation.LLMChatCompletionProvider\n",
      "3\n",
      "7\n",
      "automata.embedding.base.EmbeddingHandler\n",
      "automata.config.openai_agent.OpenAIAutomataAgentConfig\n",
      "automata.code_parsers.py.context_processing.context_handler.PyContextHandler\n",
      "automata.code_parsers.directory.DirectoryManager\n",
      "automata.symbol_embedding.base.SymbolEmbedding\n",
      "2\n",
      "11\n",
      "10\n",
      "automata.tasks.base.TaskEnvironment\n",
      "1\n",
      "automata.memory_store.symbol_code_embedding.SymbolCodeEmbeddingHandler\n",
      "13\n",
      "automata.config.openai_agent.OpenAIAutomataAgentConfigBuilder\n",
      "automata.symbol.base.ISymbolProvider\n",
      "automata.tools.builders.context_oracle.ContextOracleToolkitBuilder\n",
      "automata.code_parsers.py.context_processing.context_retriever.PyContextRetriever\n",
      "12\n",
      "14\n",
      "automata.code_parsers.directory.Directory\n",
      "automata.code_parsers.py.context_processing.context_retriever.BaseContextComponent\n",
      "15\n",
      "automata.tasks.agent_database.AutomataAgentTaskDatabase\n",
      "automata.memory_store.symbol_doc_embedding.SymbolDocEmbeddingHandler\n",
      "automata.tasks.agent_database.AutomataTaskRegistry\n",
      "automata.context_providers.symbol_synchronization.SymbolProviderSynchronizationContext\n",
      "16\n",
      "19\n",
      "automata.tasks.base.TaskStatus\n",
      "automata.llm.foundation.LLMConversationDatabaseProvider\n",
      "automata.symbol_embedding.base.SymbolDocEmbedding\n",
      "18\n",
      "automata.core.utils.LoggingConfig\n",
      "automata.code_parsers.py.context_processing.context_retriever.InterfaceContextComponent.generate\n",
      "automata.llm.providers.openai.OpenAIConversation\n",
      "automata.agent.providers.OpenAIAutomataAgent._get_next_user_response\n",
      "automata.llm.providers.openai.OpenAIChatMessage\n",
      "automata.tasks.base.Task.__init__\n",
      "17\n",
      "automata.code_parsers.py.context_processing.context_retriever.InterfaceContextComponent._process_classes_and_methods\n",
      "automata.symbol_embedding.base.SymbolCodeEmbedding\n",
      "automata.tools.base.Tool\n",
      "automata.llm.providers.openai.OpenAIChatCompletionResult\n",
      "automata.symbol.graph.references.ReferenceProcessor\n",
      "automata.symbol_embedding.vector_databases.JSONSymbolEmbeddingVectorDatabase\n",
      "automata.embedding.base.Embedding\n",
      "automata.llm.providers.openai.OpenAIChatCompletionProvider.process_delta\n",
      "automata.cli.scripts.run_agent.main\n",
      "20\n",
      "21\n",
      "automata.tasks.tasks.AutomataTask\n",
      "automata.agent.providers.OpenAIAgentToolkitBuilder\n",
      "automata.experimental.search.symbol_search.SymbolSearch.__init__\n",
      "automata.code_parsers.py.context_processing.context_handler.PyContextHandler.construct_symbol_context\n",
      "automata.symbol.symbol_utils.get_rankable_symbols\n",
      "22\n",
      "\n",
      "Example 1\n",
      "=========\n",
      "\n",
      "*User*\n",
      "  Fetch the source code for `automata.core.base.agent import AgentToolProviders`.\n",
      "\n",
      "*Assistant*\n",
      "    function_call:\n",
      "      {\n",
      "        'name': 'py-retriever-retrieve-code', \n",
      "        'arguments': '{\"module_path\": \"automata.core.base.agent\", \"object_path\": \"AgentToolProviders\"}'\n",
      "      }\n",
      "\n",
      "*User*\n",
      "  Execution Result:\n",
      "\n",
      "  class AgentToolProviders(Enum):\n",
      "    PY_READER = \"py_reader\"\n",
      "    PY_WRITER = \"py_writer\"\n",
      "    SYMBOL_SEARCH = \"symbol_search\"\n",
      "    CONTEXT_ORACLE = \"context_oracle\"\n",
      "\n",
      "  NOTE - you are at iteration 2 out of a maximum of 5. Please return a result with call_termination when ready.\n",
      "*Assistant*\n",
      "  function_call:\n",
      "  {\n",
      "    'name': 'call_termination',\n",
      "    'arguments': '{\"result\": \"```python\\n class AgentToolProviders(Enum):\\n   PY_READER = \\'py_reader\\'\\n   PY_WRITER = \\'py_writer\\'\\n   SYMBOL_SEARCH = \\'symbol_search\\'\\n   CONTEXT_ORACLE = \\'context_oracle\\'\\n```\"}'\n",
      "  }\n",
      "\n",
      "\n",
      "Example 2\n",
      "=======\n",
      "\n",
      "*Note - In this more advanced case conversation is truncated in some parts*\n",
      "\n",
      "*User*\n",
      "  Return an answer in Markdown text which completely resolves the following issue:\n",
      "    \n",
      "    Github Issue Title  \n",
      "    Refactor DocEmbeddingHandler to better follow the Single Responsibility Principle\n",
      "\n",
      "    Github Issue Description\n",
      "    The current implementation of SymbolDocEmbeddingHandler performs multiple operations related to symbol documentation embedding. This makes the class harder to maintain, test, and reason about. To improve this, we need to refactor the class to better adhere to the Single Responsibility Principle.\n",
      "\n",
      "    Two major responsibilities stand out:\n",
      "\n",
      "    Embedding Management: This covers processing, updating, and building of symbol documentation embeddings.\n",
      "    Context Retrieval and Search: This involves retrieving Python contexts for symbols and generating search lists for symbols.\n",
      "    Proposed Changes\n",
      "\n",
      "    Embedding Management: Create a new class, EmbeddingManager, to handle operations like processing existing embeddings, building new ones, and updating existing ones.\n",
      "    Context Retrieval and Search: Create a new class, ContextAndSearchHandler, to manage the retrieval of Python contexts for symbols and the generation of relevant search lists.\n",
      "    By making these changes, the SymbolDocEmbeddingHandler class will become more focused and manageable, thereby adhering more closely to the Single Responsibility Principle. This task will involve careful refactoring and thorough testing to ensure all functionality remains intact after the changes.\n",
      "    \n",
      "\n",
      "*Assistant*\n",
      "  function_call:\n",
      "    {\n",
      "      'name': 'context_oracle', \n",
      "      'arguments': '{\"query\": \"SymbolDocEmbeddingHandler\"}'\n",
      "    }\n",
      "\n",
      "*User*\n",
      "  Execution Result:\n",
      "\n",
      "  class SymbolDocEmbeddingHandler(SymbolEmbeddingHandler):\n",
      "      \"\"\"\n",
      "      Handles a database and provider for `Symbol` documentation embeddings.\n",
      "      TODO: Add more robust logic for documentation updates.\n",
      "      \"\"\"\n",
      "\n",
      "      ...CODE CONTINUES...\n",
      "\n",
      "*Assistant*\n",
      "  function_call:\n",
      "    {\n",
      "      'name': 'context_oracle', \n",
      "      'arguments': '{\"query\": \"SymbolEmbeddingHandler\"}'\n",
      "    }\n",
      "\n",
      "*User*\n",
      "  Execution Result:\n",
      "\n",
      "  ...CODE CONTINUES...\n",
      "\n",
      "*Assistant*\n",
      "  content:\n",
      "    Let us first analyze the pros and cons of this implementation before directly returning a result.\n",
      "    Based on the current implementation of `SymbolDocEmbedding`, and its context, we can propose the following changes to make it more robust:\n",
      "    ...CODE CONTINUES...\n",
      "\n",
      "*User*\n",
      "  Continue...\n",
      "\n",
      "  NOTE - YOU HAVE EXCEEDED YOUR MAXIMUM ALLOWABLE ITERATIONS, RETURN A RESULT NOW WITH call_termination.\n",
      "\n",
      "*Assistant*\n",
      "  function_call:\n",
      "    {\n",
      "      'name': 'call_termination', \n",
      "      'arguments': '{\"result\": \"```python\\nclass  SymbolDocEmbeddingHandler(SymbolEmbeddingHandler): ...CODE CONTINUES...```\"}'\n",
      "    }\n",
      "\n",
      "Note, the examples above are meant to provide necessary context to show the nature of the system.  In production, the string '...CODE CONTINUES...' would be replaced with the actual code.  Your job then is to generate the code based on the given context.\n",
      "\n",
      "\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36mDEBUG:automata.agent.providers:\n",
      "------------------------------------------------------------\n",
      "Session ID: 621c3c2f-5623-45fe-8df2-0161868d39e2\n",
      "------------------------------------------------------------\n",
      "\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Initialize the agent\n",
    "# instructions = \"Explain how OpenAI is used by the codebase. Note in particularly how it is used in embeddings and how agents consume it\"\n",
    "instructions = \"Provide a comprehensive explanation of how SymbolRank and SymbolSearch work. Return your answer as a valid JSON string.\"\n",
    "import textwrap\n",
    "# instructions = textwrap.dedent('''\n",
    "# Your task is to solve the following Github Issue\n",
    "\n",
    "# Title:\n",
    "# Specify list of supported symbols for document generation, add override flag to `EmbeddingHandler`\n",
    "\n",
    "# Body:\n",
    "# The goal is to modify the `run_doc_embedding` script to accept an arbitrary list of new symbols to regenerate [preferably in some human readable form that is parsed]. These symbols should then overwrite existing results in the database with new documentation if necessary. To implement the second step a flag will need to be added to the EmbeddingHandler.\n",
    "\n",
    "\n",
    "# 1. Understand the Project: Review the Automata project to get a clear understanding of its goals and how it operates. This includes understanding how the document generation pipeline works, the role of indices and embeddings, and how they interplay to allow for efficient code and documentation generation.\n",
    "\n",
    "# 2. Setup the Environment: Clone the Automata project into the \"../repo_store/automata\" directory relative to your local working directory.\n",
    "\n",
    "#     Code: `git clone git@github.com:emrgnt-cmplxty/Automata.git ../repo_store/automata`\n",
    "\n",
    "# 3. Generate New Indices: Once you have cloned the Automata project, navigate to the \"scripts\" directory and run the `generate_indices.sh` script to generate new indices.\n",
    "\n",
    "#     Code: \n",
    "#     ```bash\n",
    "#     cd scripts\n",
    "#     ./generate_indices.sh\n",
    "#     ```\n",
    "\n",
    "#     You can verify the creation of the indices by navigating to the `automata-embedding-data` directory and running `git status`.\n",
    "\n",
    "#     Code: \n",
    "#     ```bash\n",
    "#     cd automata-embedding-data\n",
    "#     git status\n",
    "#     ```\n",
    "# 4. Refresh Code Embeddings: From your main directory, run the `run-code-embedding` command. This will refresh the embeddings in the database, rolling the commit hash forward where the symbol source code hasn't changed and recalculating the index where necessary.\n",
    "\n",
    "#     Code: `poetry run automata run-code-embedding`\n",
    "\n",
    "# 5. Run Document Embedding: Next, run the `run-doc-embedding` command locally to see it in action.\n",
    "\n",
    "#     Code: `poetry run automata run-doc-embedding`\n",
    "\n",
    "#     This command generates new docs for newly added symbols and moves forward with the symbols that are in the index and map onto the database. This is a crucial part of the pipeline which generates the Automata docs.\n",
    "\n",
    "# 6. Understand the Codebase: As you carry out these steps, ensure to take mental notes to understand the workings of the codebase. Insert print statements and other debug aids to get a sense of what's happening in the pipeline.\n",
    "\n",
    "# 7. Modify `run_doc_embedding`: Once you are confident with your understanding of the pipeline, your goal is to modify `run_doc_embedding` to accept a list of new symbols to regenerate, and overwrite existing results in the database with new documentation if necessary.\n",
    "\n",
    "# 8. Seek Help: If you encounter any issues or have questions, don't hesitate to ask for help. Once you have successfully carried out these tasks, check in for the next steps.\n",
    "\n",
    "# Remember, understanding the pipeline and how everything fits together is the key to this task. \n",
    "\n",
    "# Begin now.\n",
    "# ''')\n",
    "instructions = \"retrieve the source code for the VectorDatabaseProvider\"\n",
    "agent = OpenAIAutomataAgent(instructions, config=agent_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4cad1214",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36mDEBUG:root:\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Latest Assistant Message -- \n",
      "\u001b[0m\n",
      "\u001b[36mDEBUG:automata.llm.providers.openai:Approximately 2454 tokens were consumed prior to completion generation.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mFunction\u001b[0m \u001b[32mCall:\n",
      "py-retriever-retrieve-raw-code\n",
      "\n",
      "Arguments:\n",
      "{\n",
      "\u001b[0m \u001b[32m\u001b[0m \u001b[32m\"module_path\":\u001b[0m \u001b[32m\"automata.core.base.database.vector\",\n",
      "\u001b[0m \u001b[32m\u001b[0m \u001b[32m\"node_path\":\u001b[0m \u001b[32m\"VectorDatabaseProvider\"\n",
      "}\n",
      "\n",
      "\u001b[0m "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36mDEBUG:automata.llm.providers.openai:Approximately 2458 tokens were after adding the latest message.\u001b[0m\n",
      "\u001b[36mDEBUG:root:\n",
      "------------------------------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[36mDEBUG:automata.agent.providers:Latest User Message -- \n",
      "user:\n",
      "content=Execution Result:\n",
      "\n",
      "class VectorDatabaseProvider(abc.ABC, Generic[K, V]):\n",
      "\n",
      "    @abc.abstractmethod\n",
      "    def __len__(self) -> int:\n",
      "        pass\n",
      "\n",
      "    @abc.abstractmethod\n",
      "    def save(self) -> None:\n",
      "        pass\n",
      "\n",
      "    @abc.abstractmethod\n",
      "    def load(self) -> None:\n",
      "        pass\n",
      "\n",
      "    @abc.abstractmethod\n",
      "    def clear(self) -> None:\n",
      "        pass\n",
      "\n",
      "    @abc.abstractmethod\n",
      "    def get_ordered_keys(self) -> List[K]:\n",
      "        pass\n",
      "\n",
      "    @abc.abstractmethod\n",
      "    def get_ordered_embeddings(self) -> List[V]:\n",
      "        pass\n",
      "\n",
      "    @abc.abstractmethod\n",
      "    def add(self, entry: V) -> None:\n",
      "        pass\n",
      "\n",
      "    @abc.abstractmethod\n",
      "    def batch_add(self, entries: V) -> None:\n",
      "        pass\n",
      "\n",
      "    @abc.abstractmethod\n",
      "    def update_entry(self, entry: V) -> None:\n",
      "        pass\n",
      "\n",
      "    @abc.abstractmethod\n",
      "    def batch_update(self, entries: List[V]) -> None:\n",
      "        pass\n",
      "\n",
      "    @abc.abstractmethod\n",
      "    def entry_to_key(self, entry: V) -> K:\n",
      "        pass\n",
      "\n",
      "    @abc.abstractmethod\n",
      "    def contains(self, key: K) -> bool:\n",
      "        pass\n",
      "\n",
      "    @abc.abstractmethod\n",
      "    def get(self, key: K) -> V:\n",
      "        pass\n",
      "\n",
      "    @abc.abstractmethod\n",
      "    def batch_get(self, keys: List[K]) -> List[V]:\n",
      "        pass\n",
      "\n",
      "    @abc.abstractmethod\n",
      "    def discard(self, key: K) -> None:\n",
      "        pass\n",
      "\n",
      "    @abc.abstractmethod\n",
      "    def batch_discard(self, keys: List[K]) -> None:\n",
      "        pass\n",
      "\n",
      "STATUS NOTES:\n",
      "YOU HAVE EXCEEDED YOUR MAXIMUM ALLOWABLE ITERATIONS, RETURN A RESULT NOW WITH call_termination.\n",
      "function_call=None\n",
      "\u001b[0m\n",
      "\u001b[36mDEBUG:automata.llm.providers.openai:Approximately 2834 tokens were after adding the latest message.\u001b[0m\n",
      "\u001b[36mDEBUG:root:\n",
      "------------------------------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[36mDEBUG:root:\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Latest Assistant Message -- \n",
      "\u001b[0m\n",
      "\u001b[36mDEBUG:automata.llm.providers.openai:Approximately 2834 tokens were consumed prior to completion generation.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mFunction\u001b[0m \u001b[32mCall:\n",
      "call_termination\n",
      "\n",
      "Arguments:\n",
      "{\"result\":\u001b[0m \u001b[32m\"```python\\nclass\u001b[0m \u001b[32mVectorDatabaseProvider(abc.ABC,\u001b[0m \u001b[32mGeneric[K,\u001b[0m \u001b[32mV]):\\n\\n\u001b[0m \u001b[32m\u001b[0m \u001b[32m\u001b[0m \u001b[32m\u001b[0m \u001b[32m@abc.abstractmethod\\n\u001b[0m \u001b[32m\u001b[0m \u001b[32m\u001b[0m \u001b[32m\u001b[0m \u001b[32mdef\u001b[0m \u001b[32m__len__(self)\u001b[0m \u001b[32m->\u001b[0m \u001b[32mint:\\n\u001b[0m \u001b[32m\u001b[0m \u001b[32m\u001b[0m \u001b[32m\u001b[0m \u001b[32m\u001b[0m \u001b[32m\u001b[0m \u001b[32m\u001b[0m \u001b[32m\u001b[0m \u001b[32mpass\\n\\n\u001b[0m \u001b[32m\u001b[0m \u001b[32m\u001b[0m \u001b[32m\u001b[0m \u001b[32m@abc.abstractmethod\\n\u001b[0m \u001b[32m\u001b[0m \u001b[32m\u001b[0m \u001b[32m\u001b[0m \u001b[32mdef\u001b[0m \u001b[32msave(self)\u001b[0m \u001b[32m->\u001b[0m \u001b[32mNone:\\n\u001b[0m \u001b[32m\u001b[0m \u001b[32m\u001b[0m \u001b[32m\u001b[0m \u001b[32m\u001b[0m \u001b[32m\u001b[0m \u001b[32m\u001b[0m \u001b[32m\u001b[0m \u001b[32mpass\\n\\n\u001b[0m \u001b[32m\u001b[0m \u001b[32m\u001b[0m \u001b[32m\u001b[0m \u001b[32m@abc.abstractmethod\\n\u001b[0m \u001b[32m\u001b[0m \u001b[32m\u001b[0m \u001b[32m\u001b[0m \u001b[32mdef\u001b[0m \u001b[32mload(self)\u001b[0m \u001b[32m->\u001b[0m \u001b[32mNone:\\n\u001b[0m \u001b[32m\u001b[0m \u001b[32m\u001b[0m \u001b[32m\u001b[0m \u001b[32m\u001b[0m \u001b[32m\u001b[0m \u001b[32m\u001b[0m \u001b[32m\u001b[0m \u001b[32mpass\\n\\n\u001b[0m \u001b[32m\u001b[0m \u001b[32m\u001b[0m \u001b[32m\u001b[0m \u001b[32m@abc.abstractmethod\\n\u001b[0m \u001b[32m\u001b[0m \u001b[32m\u001b[0m \u001b[32m\u001b[0m \u001b[32mdef\u001b[0m \u001b[32mclear(self)\u001b[0m \u001b[32m->\u001b[0m \u001b[32mNone:\\n\u001b[0m \u001b[32m\u001b[0m \u001b[32m\u001b[0m \u001b[32m\u001b[0m \u001b[32m\u001b[0m \u001b[32m\u001b[0m \u001b[32m\u001b[0m \u001b[32m\u001b[0m \u001b[32mpass\\n\\n\u001b[0m \u001b[32m\u001b[0m \u001b[32m\u001b[0m \u001b[32m\u001b[0m \u001b[32m@abc.abstractmethod\\n\u001b[0m \u001b[32m\u001b[0m \u001b[32m\u001b[0m \u001b[32m\u001b[0m \u001b[32mdef\u001b[0m \u001b[32mget_ordered_keys(self)\u001b[0m \u001b[32m->\u001b[0m \u001b[32mList[K]:\\n\u001b[0m \u001b[32m\u001b[0m \u001b[32m\u001b[0m \u001b[32m\u001b[0m \u001b[32m\u001b[0m \u001b[32m\u001b[0m \u001b[32m\u001b[0m \u001b[32m\u001b[0m \u001b[32mpass\\n\\n\u001b[0m \u001b[32m\u001b[0m \u001b[32m\u001b[0m \u001b[32m\u001b[0m \u001b[32m@abc.abstractmethod\\n\u001b[0m \u001b[32m\u001b[0m \u001b[32m\u001b[0m \u001b[32m\u001b[0m \u001b[32mdef\u001b[0m \u001b[32mget_ordered_embeddings(self)\u001b[0m \u001b[32m->\u001b[0m \u001b[32mList[V]:\\n\u001b[0m \u001b[32m\u001b[0m \u001b[32m\u001b[0m \u001b[32m\u001b[0m \u001b[32m\u001b[0m \u001b[32m\u001b[0m \u001b[32m\u001b[0m \u001b[32m\u001b[0m \u001b[32mpass\\n\\n\u001b[0m \u001b[32m\u001b[0m \u001b[32m\u001b[0m \u001b[32m\u001b[0m \u001b[32m@abc.abstractmethod\\n\u001b[0m \u001b[32m\u001b[0m \u001b[32m\u001b[0m \u001b[32m\u001b[0m \u001b[32mdef\u001b[0m \u001b[32madd(self,\u001b[0m \u001b[32mentry:\u001b[0m \u001b[32mV)\u001b[0m \u001b[32m->\u001b[0m \u001b[32mNone:\\n\u001b[0m \u001b[32m\u001b[0m \u001b[32m\u001b[0m \u001b[32m\u001b[0m \u001b[32m\u001b[0m \u001b[32m\u001b[0m \u001b[32m\u001b[0m \u001b[32m\u001b[0m \u001b[32mpass\\n\\n\u001b[0m \u001b[32m\u001b[0m \u001b[32m\u001b[0m \u001b[32m\u001b[0m \u001b[32m@abc.abstractmethod\\n\u001b[0m \u001b[32m\u001b[0m \u001b[32m\u001b[0m \u001b[32m\u001b[0m \u001b[32mdef\u001b[0m \u001b[32mbatch_add(self,\u001b[0m \u001b[32mentries:\u001b[0m \u001b[32mV)\u001b[0m \u001b[32m->\u001b[0m \u001b[32mNone:\\n\u001b[0m \u001b[32m\u001b[0m \u001b[32m\u001b[0m \u001b[32m\u001b[0m \u001b[32m\u001b[0m \u001b[32m\u001b[0m \u001b[32m\u001b[0m \u001b[32m\u001b[0m \u001b[32mpass\\n\\n\u001b[0m \u001b[32m\u001b[0m \u001b[32m\u001b[0m \u001b[32m\u001b[0m \u001b[32m@abc.abstractmethod\\n\u001b[0m \u001b[32m\u001b[0m \u001b[32m\u001b[0m \u001b[32m\u001b[0m \u001b[32mdef\u001b[0m \u001b[32mupdate_entry(self,\u001b[0m \u001b[32mentry:\u001b[0m \u001b[32mV)\u001b[0m \u001b[32m->\u001b[0m \u001b[32mNone:\\n\u001b[0m \u001b[32m\u001b[0m \u001b[32m\u001b[0m \u001b[32m\u001b[0m \u001b[32m\u001b[0m \u001b[32m\u001b[0m \u001b[32m\u001b[0m \u001b[32m\u001b[0m \u001b[32mpass\\n\\n\u001b[0m \u001b[32m\u001b[0m \u001b[32m\u001b[0m \u001b[32m\u001b[0m \u001b[32m@abc.abstractmethod\\n\u001b[0m \u001b[32m\u001b[0m \u001b[32m\u001b[0m \u001b[32m\u001b[0m \u001b[32mdef\u001b[0m \u001b[32mbatch_update(self,\u001b[0m \u001b[32mentries:\u001b[0m \u001b[32mList[V])\u001b[0m \u001b[32m->\u001b[0m \u001b[32mNone:\\n\u001b[0m \u001b[32m\u001b[0m \u001b[32m\u001b[0m \u001b[32m\u001b[0m \u001b[32m\u001b[0m \u001b[32m\u001b[0m \u001b[32m\u001b[0m \u001b[32m\u001b[0m \u001b[32mpass\\n\\n\u001b[0m \u001b[32m\u001b[0m \u001b[32m\u001b[0m \u001b[32m\u001b[0m \u001b[32m@abc.abstractmethod\\n\u001b[0m \u001b[32m\u001b[0m \u001b[32m\u001b[0m \u001b[32m\u001b[0m \u001b[32mdef\u001b[0m \u001b[32mentry_to_key(self,\u001b[0m \u001b[32mentry:\u001b[0m \u001b[32mV)\u001b[0m \u001b[32m->\u001b[0m \u001b[32mK:\\n\u001b[0m \u001b[32m\u001b[0m \u001b[32m\u001b[0m \u001b[32m\u001b[0m \u001b[32m\u001b[0m \u001b[32m\u001b[0m \u001b[32m\u001b[0m \u001b[32m\u001b[0m \u001b[32mpass\\n\\n\u001b[0m \u001b[32m\u001b[0m \u001b[32m\u001b[0m \u001b[32m\u001b[0m \u001b[32m@abc.abstractmethod\\n\u001b[0m \u001b[32m\u001b[0m \u001b[32m\u001b[0m \u001b[32m\u001b[0m \u001b[32mdef\u001b[0m \u001b[32mcontains(self,\u001b[0m \u001b[32mkey:\u001b[0m \u001b[32mK)\u001b[0m \u001b[32m->\u001b[0m \u001b[32mbool:\\n\u001b[0m \u001b[32m\u001b[0m \u001b[32m\u001b[0m \u001b[32m\u001b[0m \u001b[32m\u001b[0m \u001b[32m\u001b[0m \u001b[32m\u001b[0m \u001b[32m\u001b[0m \u001b[32mpass\\n\\n\u001b[0m \u001b[32m\u001b[0m \u001b[32m\u001b[0m \u001b[32m\u001b[0m \u001b[32m@abc.abstractmethod\\n\u001b[0m \u001b[32m\u001b[0m \u001b[32m\u001b[0m \u001b[32m\u001b[0m \u001b[32mdef\u001b[0m \u001b[32mget(self,\u001b[0m \u001b[32mkey:\u001b[0m \u001b[32mK)\u001b[0m \u001b[32m->\u001b[0m \u001b[32mV:\\n\u001b[0m \u001b[32m\u001b[0m \u001b[32m\u001b[0m \u001b[32m\u001b[0m \u001b[32m\u001b[0m \u001b[32m\u001b[0m \u001b[32m\u001b[0m \u001b[32m\u001b[0m \u001b[32mpass\\n\\n\u001b[0m \u001b[32m\u001b[0m \u001b[32m\u001b[0m \u001b[32m\u001b[0m \u001b[32m@abc.abstractmethod\\n\u001b[0m \u001b[32m\u001b[0m \u001b[32m\u001b[0m \u001b[32m\u001b[0m \u001b[32mdef\u001b[0m \u001b[32mbatch_get(self,\u001b[0m \u001b[32mkeys:\u001b[0m \u001b[32mList[K])\u001b[0m \u001b[32m->\u001b[0m \u001b[32mList[V]:\\n\u001b[0m \u001b[32m\u001b[0m \u001b[32m\u001b[0m \u001b[32m\u001b[0m \u001b[32m\u001b[0m \u001b[32m\u001b[0m \u001b[32m\u001b[0m \u001b[32m\u001b[0m \u001b[32mpass\\n\\n\u001b[0m \u001b[32m\u001b[0m \u001b[32m\u001b[0m \u001b[32m\u001b[0m \u001b[32m@abc.abstractmethod\\n\u001b[0m \u001b[32m\u001b[0m \u001b[32m\u001b[0m \u001b[32m\u001b[0m \u001b[32mdef\u001b[0m \u001b[32mdiscard(self,\u001b[0m \u001b[32mkey:\u001b[0m \u001b[32mK)\u001b[0m \u001b[32m->\u001b[0m \u001b[32mNone:\\n\u001b[0m \u001b[32m\u001b[0m \u001b[32m\u001b[0m \u001b[32m\u001b[0m \u001b[32m\u001b[0m \u001b[32m\u001b[0m \u001b[32m\u001b[0m \u001b[32m\u001b[0m \u001b[32mpass\\n\\n\u001b[0m \u001b[32m\u001b[0m \u001b[32m\u001b[0m \u001b[32m\u001b[0m \u001b[32m@abc.abstractmethod\\n\u001b[0m \u001b[32m\u001b[0m \u001b[32m\u001b[0m \u001b[32m\u001b[0m \u001b[32mdef\u001b[0m \u001b[32mbatch_discard(self,\u001b[0m \u001b[32mkeys:\u001b[0m \u001b[32mList[K])\u001b[0m \u001b[32m->\u001b[0m \u001b[32mNone:\\n\u001b[0m \u001b[32m\u001b[0m \u001b[32m\u001b[0m \u001b[32m\u001b[0m \u001b[32m\u001b[0m \u001b[32m\u001b[0m \u001b[32m\u001b[0m \u001b[32m\u001b[0m \u001b[32mpass\\n```\"}\n",
      "\n",
      "\u001b[0m "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36mDEBUG:automata.llm.providers.openai:Approximately 2838 tokens were after adding the latest message.\u001b[0m\n",
      "\u001b[36mDEBUG:root:\n",
      "------------------------------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[36mDEBUG:automata.agent.providers:Latest User Message -- \n",
      "user:\n",
      "content=Execution Result:\n",
      "\n",
      "```python\n",
      "class VectorDatabaseProvider(abc.ABC, Generic[K, V]):\n",
      "\n",
      "    @abc.abstractmethod\n",
      "    def __len__(self) -> int:\n",
      "        pass\n",
      "\n",
      "    @abc.abstractmethod\n",
      "    def save(self) -> None:\n",
      "        pass\n",
      "\n",
      "    @abc.abstractmethod\n",
      "    def load(self) -> None:\n",
      "        pass\n",
      "\n",
      "    @abc.abstractmethod\n",
      "    def clear(self) -> None:\n",
      "        pass\n",
      "\n",
      "    @abc.abstractmethod\n",
      "    def get_ordered_keys(self) -> List[K]:\n",
      "        pass\n",
      "\n",
      "    @abc.abstractmethod\n",
      "    def get_ordered_embeddings(self) -> List[V]:\n",
      "        pass\n",
      "\n",
      "    @abc.abstractmethod\n",
      "    def add(self, entry: V) -> None:\n",
      "        pass\n",
      "\n",
      "    @abc.abstractmethod\n",
      "    def batch_add(self, entries: V) -> None:\n",
      "        pass\n",
      "\n",
      "    @abc.abstractmethod\n",
      "    def update_entry(self, entry: V) -> None:\n",
      "        pass\n",
      "\n",
      "    @abc.abstractmethod\n",
      "    def batch_update(self, entries: List[V]) -> None:\n",
      "        pass\n",
      "\n",
      "    @abc.abstractmethod\n",
      "    def entry_to_key(self, entry: V) -> K:\n",
      "        pass\n",
      "\n",
      "    @abc.abstractmethod\n",
      "    def contains(self, key: K) -> bool:\n",
      "        pass\n",
      "\n",
      "    @abc.abstractmethod\n",
      "    def get(self, key: K) -> V:\n",
      "        pass\n",
      "\n",
      "    @abc.abstractmethod\n",
      "    def batch_get(self, keys: List[K]) -> List[V]:\n",
      "        pass\n",
      "\n",
      "    @abc.abstractmethod\n",
      "    def discard(self, key: K) -> None:\n",
      "        pass\n",
      "\n",
      "    @abc.abstractmethod\n",
      "    def batch_discard(self, keys: List[K]) -> None:\n",
      "        pass\n",
      "```\n",
      "function_call=None\n",
      "\u001b[0m\n",
      "\u001b[36mDEBUG:automata.llm.providers.openai:Approximately 3195 tokens were after adding the latest message.\u001b[0m\n",
      "\u001b[36mDEBUG:root:\n",
      "------------------------------------------------------------------------------------------------------------------------\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Run the agent\n",
    "result = agent.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8809bae0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result:\n",
      "Execution Result:\n",
      "\n",
      "```python\n",
      "class VectorDatabaseProvider(abc.ABC, Generic[K, V]):\n",
      "\n",
      "    @abc.abstractmethod\n",
      "    def __len__(self) -> int:\n",
      "        pass\n",
      "\n",
      "    @abc.abstractmethod\n",
      "    def save(self) -> None:\n",
      "        pass\n",
      "\n",
      "    @abc.abstractmethod\n",
      "    def load(self) -> None:\n",
      "        pass\n",
      "\n",
      "    @abc.abstractmethod\n",
      "    def clear(self) -> None:\n",
      "        pass\n",
      "\n",
      "    @abc.abstractmethod\n",
      "    def get_ordered_keys(self) -> List[K]:\n",
      "        pass\n",
      "\n",
      "    @abc.abstractmethod\n",
      "    def get_ordered_embeddings(self) -> List[V]:\n",
      "        pass\n",
      "\n",
      "    @abc.abstractmethod\n",
      "    def add(self, entry: V) -> None:\n",
      "        pass\n",
      "\n",
      "    @abc.abstractmethod\n",
      "    def batch_add(self, entries: V) -> None:\n",
      "        pass\n",
      "\n",
      "    @abc.abstractmethod\n",
      "    def update_entry(self, entry: V) -> None:\n",
      "        pass\n",
      "\n",
      "    @abc.abstractmethod\n",
      "    def batch_update(self, entries: List[V]) -> None:\n",
      "        pass\n",
      "\n",
      "    @abc.abstractmethod\n",
      "    def entry_to_key(self, entry: V) -> K:\n",
      "        pass\n",
      "\n",
      "    @abc.abstractmethod\n",
      "    def contains(self, key: K) -> bool:\n",
      "        pass\n",
      "\n",
      "    @abc.abstractmethod\n",
      "    def get(self, key: K) -> V:\n",
      "        pass\n",
      "\n",
      "    @abc.abstractmethod\n",
      "    def batch_get(self, keys: List[K]) -> List[V]:\n",
      "        pass\n",
      "\n",
      "    @abc.abstractmethod\n",
      "    def discard(self, key: K) -> None:\n",
      "        pass\n",
      "\n",
      "    @abc.abstractmethod\n",
      "    def batch_discard(self, keys: List[K]) -> None:\n",
      "        pass\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "# Print the result\n",
    "print(f\"Result:\\n{result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "03e805b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'class VectorDatabaseProvider(abc.ABC, Generic[K, V]):\\n\\n    @abc.abstractmethod\\n    def __len__(self) -> int:\\n        pass\\n\\n    @abc.abstractmethod\\n    def save(self) -> None:\\n        pass\\n\\n    @abc.abstractmethod\\n    def load(self) -> None:\\n        pass\\n\\n    @abc.abstractmethod\\n    def clear(self) -> None:\\n        pass\\n\\n    @abc.abstractmethod\\n    def get_ordered_keys(self) -> List[K]:\\n        pass\\n\\n    @abc.abstractmethod\\n    def get_ordered_embeddings(self) -> List[V]:\\n        pass\\n\\n    @abc.abstractmethod\\n    def add(self, entry: V) -> None:\\n        pass\\n\\n    @abc.abstractmethod\\n    def batch_add(self, entries: V) -> None:\\n        pass\\n\\n    @abc.abstractmethod\\n    def update_entry(self, entry: V) -> None:\\n        pass\\n\\n    @abc.abstractmethod\\n    def batch_update(self, entries: List[V]) -> None:\\n        pass\\n\\n    @abc.abstractmethod\\n    def entry_to_key(self, entry: V) -> K:\\n        pass\\n\\n    @abc.abstractmethod\\n    def contains(self, key: K) -> bool:\\n        pass\\n\\n    @abc.abstractmethod\\n    def get(self, key: K) -> V:\\n        pass\\n\\n    @abc.abstractmethod\\n    def batch_get(self, keys: List[K]) -> List[V]:\\n        pass\\n\\n    @abc.abstractmethod\\n    def discard(self, key: K) -> None:\\n        pass\\n\\n    @abc.abstractmethod\\n    def batch_discard(self, keys: List[K]) -> None:\\n        pass'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = result.replace(\"Execution Result:\",\"\").replace(\"```python\",\"\").replace(\"```\",\"\").strip()\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cc9a5658",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'class VectorDatabaseProvider(abc.ABC, Generic[K, V]):\\n    \"\"\"An abstract base class for different types of vector database providers.\"\"\"\\n\\n    @abc.abstractmethod\\n    def __len__(self) -> int:\\n        pass\\n\\n    @abc.abstractmethod\\n    def save(self) -> None:\\n        \"\"\"Abstract method to save data.\"\"\"\\n        pass\\n\\n    @abc.abstractmethod\\n    def load(self) -> None:\\n        \"\"\"Abstract method to load data.\"\"\"\\n        pass\\n\\n    @abc.abstractmethod\\n    def clear(self) -> None:\\n        \"\"\"Abstract method to clear all entries.\"\"\"\\n        pass\\n\\n    @abc.abstractmethod\\n    def get_ordered_keys(self) -> List[K]:\\n        \"\"\"Abstract method to get all keys stored in the database.\"\"\"\\n        pass\\n\\n    @abc.abstractmethod\\n    def get_ordered_embeddings(self) -> List[V]:\\n        \"\"\"\\n        Abstract method to get an ordered list entries in the database.\\n        These vectors should be ordered in the same way as the keys returned by get_ordered_keys.\\n        \"\"\"\\n        pass\\n\\n    @abc.abstractmethod\\n    def add(self, entry: V) -> None:\\n        \"\"\"Abstract method to add an entry to the database.\"\"\"\\n        pass\\n\\n    @abc.abstractmethod\\n    def batch_add(self, entries: V) -> None:\\n        \"\"\"Abstract method to add a batch of specific entries to the database.\"\"\"\\n        pass\\n\\n    @abc.abstractmethod\\n    def update_entry(self, entry: V) -> None:\\n        \"\"\"Abstract method to update a specific entry.\"\"\"\\n        pass\\n\\n    @abc.abstractmethod\\n    def batch_update(self, entries: List[V]) -> None:\\n        \"\"\"Abstract method to update a list of specific entries.\"\"\"\\n        pass\\n\\n    @abc.abstractmethod\\n    def entry_to_key(self, entry: V) -> K:\\n        \"\"\"Abstract method to generate a unique hashable key from an entry of type V.\"\"\"\\n        pass\\n\\n    @abc.abstractmethod\\n    def contains(self, key: K) -> bool:\\n        \"\"\"Abstract method to check if a specific entry is present in the database.\"\"\"\\n        pass\\n\\n    @abc.abstractmethod\\n    def get(self, key: K) -> V:\\n        \"\"\"Abstract method to get a specific entry.\"\"\"\\n        pass\\n\\n    @abc.abstractmethod\\n    def batch_get(self, keys: List[K]) -> List[V]:\\n        \"\"\"Abstract method to get a batch of specific entries.\"\"\"\\n        pass\\n\\n    @abc.abstractmethod\\n    def discard(self, key: K) -> None:\\n        \"\"\"Abstract method to discard a specific entry.\"\"\"\\n        pass\\n\\n    @abc.abstractmethod\\n    def batch_discard(self, keys: List[K]) -> None:\\n        \"\"\"Abstract method to discard a batch of specific entries.\"\"\"\\n        pass'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = py_reader.get_source_code(\"automata.core.base.database.vector\", \"VectorDatabaseProvider\")\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a49b6e77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x==y"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
