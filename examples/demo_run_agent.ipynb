{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "019bfa33",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mLoading modules with root path: /Users/nolantremelling/automata/automata/core/../.. and py path: /Users/nolantremelling/automata/automata/core/../../automata\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "\n",
    "from automata.cli.commands import reconfigure_logging\n",
    "from automata.config.config_base import AgentConfigName\n",
    "from automata.config.openai_config import OpenAIAutomataAgentConfigBuilder\n",
    "from automata.agent.openai_agent import OpenAIAutomataAgent\n",
    "from automata.singletons.dependency_factory import dependency_factory\n",
    "from automata.singletons.py_module_loader import py_module_loader\n",
    "from automata.tools.agent_tool_factory import AgentToolFactory\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "reconfigure_logging(\"DEBUG\")\n",
    "\n",
    "py_module_loader.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9852e2c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mBuilding dependencies for toolkits ['document-oracle', 'py-reader']...\u001b[0m\n",
      "\u001b[32mBuilding symbol_search...\u001b[0m\n",
      "\u001b[32mCreating dependency symbol_search\u001b[0m\n",
      "\u001b[32mCreating dependency symbol_graph\u001b[0m\n",
      "\u001b[32mCreating dependency symbol_code_embedding_handler\u001b[0m\n",
      "\u001b[32mAnonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.\u001b[0m\n",
      "\u001b[32mSuccessfully imported ClickHouse Connect C data optimizations\u001b[0m\n",
      "\u001b[36mSuccessfully import ClickHouse Connect C/Numpy optimizations\u001b[0m\n",
      "\u001b[32mUsing python library for writing JSON byte strings\u001b[0m\n",
      "\u001b[32mloaded in 971 embeddings\u001b[0m\n",
      "\u001b[32mloaded in 1 collections\u001b[0m\n",
      "\u001b[36mStarting component System\u001b[0m\n",
      "\u001b[36mStarting component Posthog\u001b[0m\n",
      "\u001b[36mStarting component PersistentDuckDB\u001b[0m\n",
      "\u001b[36mStarting component LocalAPI\u001b[0m\n",
      "\u001b[32mcollection with name automata already exists, returning existing collection\u001b[0m\n",
      "\u001b[32mCreating dependency embedding_similarity_calculator\u001b[0m\n",
      "\u001b[32mBuilding symbol_doc_embedding_handler...\u001b[0m\n",
      "\u001b[32mCreating dependency symbol_doc_embedding_handler\u001b[0m\n",
      "\u001b[32mAnonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.\u001b[0m\n",
      "\u001b[32mloaded in 791 embeddings\u001b[0m\n",
      "\u001b[32mloaded in 1 collections\u001b[0m\n",
      "\u001b[36mStarting component System\u001b[0m\n",
      "\u001b[36mStarting component Posthog\u001b[0m\n",
      "\u001b[36mStarting component PersistentDuckDB\u001b[0m\n",
      "\u001b[36mStarting component LocalAPI\u001b[0m\n",
      "\u001b[32mcollection with name automata already exists, returning existing collection\u001b[0m\n",
      "\u001b[32mCreating dependency py_context_handler\u001b[0m\n",
      "\u001b[32mCreating dependency py_context_retriever\u001b[0m\n",
      "\u001b[32mBuilding py_reader...\u001b[0m\n",
      "\u001b[32mCreating dependency py_reader\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Construct the set of all dependencies that will be used to build the tools\n",
    "toolkit_list = [\"document-oracle\",\"py-reader\"]\n",
    "tool_dependencies = dependency_factory.build_dependencies_for_tools(toolkit_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb0430f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the tools\n",
    "tools = AgentToolFactory.build_tools(toolkit_list, **tool_dependencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e5b36ce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mCreating dependency symbol_rank\u001b[0m\n",
      "\u001b[32mCreating dependency subgraph\u001b[0m\n",
      "\u001b[32mPre-computing bounding boxes for all rankable symbols\u001b[0m\n",
      "\u001b[32mFinished pre-computing bounding boxes for all rankable symbols in 2.469158887863159 seconds\u001b[0m\n",
      "\u001b[32mBuilding the rankable symbol subgraph...\u001b[0m\n",
      "100%|██████████| 791/791 [00:06<00:00, 115.68it/s]\n",
      "\u001b[32mBuilt the rankable symbol subgraph\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Build the agent config\n",
    "config_name = AgentConfigName(\"automata-main\")\n",
    "\n",
    "agent_config = (\n",
    "    OpenAIAutomataAgentConfigBuilder.from_name(config_name)\n",
    "    .with_tools(tools)\n",
    "    .with_model(\"gpt-3.5-turbo\")\n",
    "    .with_max_iterations(3)\n",
    "    .build()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67aa2161",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36mSetting up agent with tools = [OpenAITool(function=<bound method DocumentOracleToolkitBuilder._get_best_match of <automata.experimental.tools.builders.document_oracle_builder.DocumentOracleOpenAIToolkitBuilder object at 0x111d45300>>, name='document-oracle', description=\"The DocumentOracleToolkitBuilder is a tool that translates a given natural language query into relevant context by finding the most semantically similar symbol's documentation in a Python codebase. It uses SymbolSearch and EmbeddingSimilarityCalculator to identify this symbol. The tool then returns the corresponding class documentation, providing valuable context for the query.\", coroutine=None, properties={'query': {'type': 'string', 'description': 'The query string to search for.'}}, required=['query'], openai_function=<automata.llm.providers.openai_llm.OpenAIFunction object at 0x1297cdf60>), OpenAITool(function=<bound method PyReaderToolkitBuilder._run_indexer_retrieve_code of <automata.tools.builders.py_reader_builder.PyReaderOpenAIToolkitBuilder object at 0x1297cc400>>, name='retrieve-code', description='Returns the code of the python package, module, standalone function, class, or method at the given module path and sub-module (e.g. node) path. If no match is found, then \"No Result Found.\" is returned.\\n\\nFor example - suppose we want the entire source code of a module located in \"target_module.py\" of the root directory,then the correct tool input is:\\narguments: {\"module_path\": \"target_module\"}Suppose instead the file is located in a subdirectory called module_directory:\\narguments: {\"module_path\": \"module_directory.target_module\"}Next, suppose that we just want to retrieve \\'target_function\\' in target_module:arguments: {\"module_path\": \"module_directory.target_module\", \"node_path\": \"target_function\"}Lastly, if the function is defined in a class, TargetClass, then the correct tool input is:\\narguments: {\"module_path\": \"module_directory.target_module\", \"node_path\": \"TargetClass.target_function\"}', coroutine=None, properties={'module_path': {'type': 'string', 'description': 'The path to the module to retrieve code from.'}, 'node_path': {'type': 'string', 'description': 'The path to the object to retrieve code from.'}}, required=['module_path'], openai_function=<automata.llm.providers.openai_llm.OpenAIFunction object at 0x1297ce9e0>), OpenAITool(function=<bound method PyReaderToolkitBuilder._run_indexer_retrieve_docstring of <automata.tools.builders.py_reader_builder.PyReaderOpenAIToolkitBuilder object at 0x1297cc400>>, name='retrieve-docstring', description='Identical to py-retriever-retrieve-code, except returns the docstring instead of raw code.', coroutine=None, properties={'module_path': {'type': 'string', 'description': 'The path to the module to retrieve code from.'}, 'node_path': {'type': 'string', 'description': 'The path to the object to retrieve code from.'}}, required=['module_path'], openai_function=<automata.llm.providers.openai_llm.OpenAIFunction object at 0x1297cebf0>)]\u001b[0m\n",
      "\u001b[36mAdding the following initial mesasge to the conversation OpenAIChatMessage(role=assistant, content=Hello, I am Automata, OpenAI's most skilled coding system. How may I assist you today?, function_call=None)\u001b[0m\n",
      "\u001b[36m\n",
      "------------------------------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[36mAdding the following initial mesasge to the conversation OpenAIChatMessage(role=user, content=Please carry out the following instruction \n",
      "Provide a markdown python snippet, which can validly executed by `exec`. When ran, the snippet produces a valid instance of an openai agent config in the local variable `x`.\n",
      ", function_call=None)\u001b[0m\n",
      "\u001b[36m\n",
      "------------------------------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[36mAdding the following initial mesasge to the conversation OpenAIChatMessage(role=assistant, content=None, function_call={\"name\": \"initializer\", \"arguments\": \"{}\"})\u001b[0m\n",
      "\u001b[36m\n",
      "------------------------------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[36mAdding the following initial mesasge to the conversation OpenAIChatMessage(role=user, content=Continue..., function_call=None)\u001b[0m\n",
      "\u001b[36m\n",
      "------------------------------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[36mInitializing with System Instruction -- \n",
      "\n",
      "You are Automata Master, an advanced autonomous software architect developed by OpenAI.  You are designed to specifically operate within local Python repositories.  With your capability to understand and process natural language instructions,  you perform tasks efficiently using your available functions. \n",
      "When you have completed your task, return the final result to the user as soon as possible via the `call_termination` function.\n",
      "\n",
      "Persistently execute multiple actions until you have amassed enough information to ensure an high likelihood of successfully completing the given task.\n",
      "\n",
      "IMPORTANT - Note that you have a maxiumum of 3 iterations to complete the task, after which point the session terminates. If you are approaching the limit, then promptly return a result.\n",
      "\n",
      "An example of the Thoughts->Function Call --> Observations --> Thoughts->Function Call --> ... chain follows below.\n",
      "\n",
      "**Example pattern**\n",
      "\n",
      "  *Assistant*\n",
      "    Hello, I am Automata, OpenAI's most skilled coding system. How may I assist you today?\n",
      "\n",
      "  *User*\n",
      "    Please carry out the following instruction Determine how to best use Automata.\n",
      "\n",
      "  *Assistant*\n",
      "    function_call:\n",
      "    {\n",
      "      'name: \"context_oracle\"\n",
      "      'arguments': '{\"query\": \"Automata\"}'\n",
      "    }\n",
      "\n",
      "  *User*\n",
      "    Execution Result:\n",
      "\n",
      "    ...RESULT CONTINUES...\n",
      "\n",
      "  *Assistant*\n",
      "    content:\n",
      "      Let us first analyze ...THOUGHT CONTINUES...\n",
      "\n",
      "  ...CONVERSATION CONTINUES...\n",
      "  \n",
      "  *Assistant*\n",
      "    function_call:\n",
      "    {\n",
      "      'name': 'call_termination', \n",
      "      'arguments': '{\"result\": \"```python\\nclass  SymbolDocEmbeddingHandler(SymbolEmbeddingHandler): ...CODE CONTINUES...```\"}'\n",
      "    }\n",
      "\n",
      "\n",
      "An overview of the most important python modules, and their internal functions and classes is given immediately below to help you in this task.\n",
      "\n",
      "automata.symbol.symbol_base.Symbol.full_dotpath\n",
      "automata.singletons.dependency_factory.DependencyFactory.get\n",
      "automata.experimental.search.symbol_search.SymbolSearch.get_symbol_rank_results\n",
      "automata.experimental.code_parsers.py.context_processing.context_retriever.InterfaceContextComponent._process_classes_and_methods\n",
      "automata.tasks.task_environment.AutomataTaskEnvironment.commit_task\n",
      "automata.symbol.symbol_parser.parse_symbol\n",
      "automata.experimental.search.symbol_rank.SymbolRank.get_ordered_ranks\n",
      "automata.config.config_base.AgentConfigBuilder._validate_type\n",
      "automata.symbol.symbol_utils.get_rankable_symbols\n",
      "automata.config.openai_config.OpenAIAutomataAgentConfigBuilder.create_from_args\n",
      "automata.core.base.database.vector_database.ChromaVectorDatabase._save\n",
      "automata.eval.agent.agent_eval_metrics.AgentEvaluationMetrics.__str__\n",
      "automata.symbol_embedding.symbol_embedding_base.SymbolEmbedding.symbol\n",
      "automata.cli.commands.reconfigure_logging\n",
      "automata.tasks.task_executor.AutomataTaskExecutor.execute\n",
      "automata.cli.scripts.run_doc_embedding.initialize_providers\n",
      "automata.singletons.py_module_loader.PyModuleLoader._assert_initialized\n",
      "automata.agent.openai_agent.OpenAIAutomataAgent.set_database_provider\n",
      "automata.tools.agent_tool_factory.AgentToolFactory.create_tools_from_builder\n",
      "automata.singletons.py_module_loader.PyModuleLoader.fetch_ast_module\n",
      "automata.cli.scripts.run_agent.main\n",
      "automata.cli.commands.configure\n",
      "automata.symbol.graph.symbol_navigator.SymbolGraphNavigator._get_symbol_references_in_scope\n",
      "automata.context_providers.symbol_synchronization_context.SymbolProviderRegistry.synchronize\n",
      "automata.cli.scripts.run_tool_eval.run_eval_harness\n",
      "automata.experimental.scripts.run_update_tool_eval.filter_and_log_symbols\n",
      "automata.tasks.task_base.Task.status\n",
      "automata.eval.tool.tool_eval.ToolEval.generate_eval_result\n",
      "automata.symbol_embedding.symbol_embedding_handler.SymbolEmbeddingHandler.__init__\n",
      "automata.symbol_embedding.symbol_embedding_base.SymbolEmbedding.__init__\n",
      "automata.llm.providers.openai_llm.OpenAIChatCompletionProvider.get_next_assistant_completion\n",
      "automata.eval.agent.agent_eval.AgentEval.process_result\n",
      "automata.experimental.tools.builders.symbol_search_builder.SymbolSearchToolkitBuilder.build_tool\n",
      "automata.cli.install_indexing.generate_local_indices\n",
      "automata.code_writers.py.py_doc_writer.PyDocWriter.generate_index_files\n",
      "automata.symbol.graph.symbol_graph.SymbolGraph.__init__\n",
      "automata.code_writers.py.py_doc_writer.PyDocWriter.generate_rst_files\n",
      "automata.symbol.symbol_utils.convert_to_ast_object\n",
      "automata.embedding.embedding_base.EmbeddingVectorProvider.build_embedding_vector\n",
      "automata.cli.scripts.run_doc_post_process.main\n",
      "automata.core.utils.get_root_fpath\n",
      "automata.llm.providers.openai_llm.OpenAIChatMessage.from_completion_result\n",
      "automata.code_parsers.directory.DirectoryManager._load_directory_structure\n",
      "automata.experimental.scripts.run_update_tool_eval.process_payload\n",
      "automata.eval.eval_base.parse_action_from_payload\n",
      "automata.symbol.symbol_base.ISymbolProvider.get_sorted_supported_symbols\n",
      "automata.llm.providers.openai_llm.OpenAIChatCompletionProvider.standalone_call\n",
      "automata.cli.env_operations.load_env_vars\n",
      "automata.symbol.graph.graph_builder.GraphBuilder.build_graph\n",
      "automata.core.base.database.vector_database.JSONVectorDatabase.entry_to_key\n",
      "automata.experimental.search.symbol_search.SymbolSearch.get_symbol_code_similarity_results\n",
      "automata.core.base.database.relational_database.SQLDatabase.select\n",
      "automata.tasks.task_base.Task.__init__\n",
      "automata.symbol.symbol_parser._SymbolParser.accept_identifier\n",
      "automata.experimental.memory_store.symbol_doc_embedding_handler.SymbolDocEmbeddingHandler._update_existing_embedding\n",
      "automata.agent.openai_agent.OpenAIAutomataAgent._setup\n",
      "automata.symbol_embedding.symbol_embedding_handler.SymbolEmbeddingHandler.flush\n",
      "automata.experimental.code_parsers.py.context_processing.context_utils.process_method\n",
      "automata.tasks.task_registry.AutomataTaskRegistry.update_task\n",
      "automata.agent.openai_agent.OpenAIAutomataAgent._build_initial_messages\n",
      "automata.experimental.scripts.run_update_tool_eval.load_and_process_data\n",
      "automata.code_writers.py.py_code_writer.PyCodeWriter.write_module_to_disk\n",
      "automata.core.run_handlers.initialize_automata\n",
      "automata.experimental.memory_store.symbol_doc_embedding_handler.SymbolDocEmbeddingHandler._create_new_embedding\n",
      "automata.experimental.tools.builders.symbol_search_builder.SymbolSearchToolkitBuilder.build\n",
      "automata.singletons.py_module_loader.PyModuleLoader.delete_module\n",
      "automata.eval.tool.tool_eval_metrics.ToolEvaluationMetrics.__str__\n",
      "automata.core.ast_handlers.find_syntax_tree_node\n",
      "automata.symbol_embedding.vector_databases.ChromaSymbolEmbeddingVectorDatabase._prepare_entries_for_insertion\n",
      "automata.code_parsers.directory.Node.__init__\n",
      "automata.code_parsers.py.dotpath_map.DotPathMap._build_module_dotpath_to_fpath_map\n",
      "automata.core.base.base_error.AutomataError.user_message\n",
      "automata.core.base.database.vector_database.ChromaVectorDatabase.__init__\n",
      "automata.core.utils.set_openai_api_key\n",
      "automata.symbol.symbol_base.SymbolDescriptor.get_escaped_name\n",
      "automata.tools.builders.py_reader_builder.PyReaderToolkitBuilder.build\n",
      "automata.symbol_embedding.symbol_embedding_base.SymbolEmbedding.from_args\n",
      "automata.config.config_base.AgentConfig._load_automata_yaml_config\n",
      "automata.code_parsers.directory.DirectoryManager.get_files_in_dir\n",
      "automata.tasks.task_environment.AutomataTaskEnvironment.setup\n",
      "automata.llm.llm_base.FunctionCall.from_response_dict\n",
      "automata.core.ast_handlers.get_node_without_docstrings\n",
      "automata.eval.tool.tool_eval_harness.ToolEvalSetLoader.__init__\n",
      "automata.llm.providers.openai_llm.OpenAIChatCompletionProvider.approximate_tokens_consumed\n",
      "automata.experimental.memory_store.symbol_doc_embedding_handler.SymbolDocEmbeddingHandler.process_embedding\n",
      "automata.symbol_embedding.vector_databases.ChromaSymbolEmbeddingVectorDatabase._construct_entry_from_result\n",
      "automata.tools.builders.py_writer_builder.PyCodeWriterToolkitBuilder._update_existing_module\n",
      "automata.memory_store.symbol_code_embedding_handler.SymbolCodeEmbeddingHandler.process_embedding\n",
      "automata.tools.builders.py_writer_builder.PyCodeWriterToolkitBuilder.build\n",
      "automata.core.run_handlers.run_with_agent\n",
      "automata.symbol_embedding.vector_databases.ChromaSymbolEmbeddingVectorDatabase._prepare_entry_for_insertion\n",
      "automata.memory_store.symbol_code_embedding_handler.SymbolCodeEmbeddingHandler.flush\n",
      "automata.experimental.code_parsers.py.context_processing.context_handler.PyContextHandler.construct_symbol_context\n",
      "automata.symbol_embedding.vector_databases.JSONSymbolEmbeddingVectorDatabase.get_ordered_keys\n",
      "automata.singletons.py_module_loader.PyModuleLoader._load_all_modules\n",
      "automata.config.config_base.PathEnum.to_path\n",
      "automata.eval.agent.agent_eval_metrics.AgentEvaluationMetrics.total_partial_matches\n",
      "automata.eval.agent.agent_eval_metrics.AgentEvaluationMetrics.total_full_matches\n",
      "automata.symbol.symbol_parser._SymbolParser.parse_descriptor\n",
      "automata.eval.agent.agent_eval_database.AgentEvalResultDatabase.write_result\n",
      "\n",
      "Example 1\n",
      "=========\n",
      "\n",
      "*User*\n",
      "  Fetch the source code for `automata.core.base.agent import AgentToolProviders`.\n",
      "\n",
      "*Assistant*\n",
      "    function_call:\n",
      "      {\n",
      "        'name': 'py-retriever-retrieve-code', \n",
      "        'arguments': '{\"module_path\": \"automata.core.base.agent\", \"node_path\": \"AgentToolProviders\"}'\n",
      "      }\n",
      "\n",
      "*User*\n",
      "  Execution Result:\n",
      "\n",
      "  class AgentToolProviders(Enum):\n",
      "    PY_READER = \"py_reader\"\n",
      "    PY_WRITER = \"py_writer\"\n",
      "    SYMBOL_SEARCH = \"symbol_search\"\n",
      "    CONTEXT_ORACLE = \"context_oracle\"\n",
      "\n",
      "  NOTE - you are at iteration 2 out of a maximum of 5. Please return a result with call_termination when ready.\n",
      "*Assistant*\n",
      "  function_call:\n",
      "  {\n",
      "    'name': 'call_termination',\n",
      "    'arguments': '{\"result\": \"```python\\n class AgentToolProviders(Enum):\\n   PY_READER = \\'py_reader\\'\\n   PY_WRITER = \\'py_writer\\'\\n   SYMBOL_SEARCH = \\'symbol_search\\'\\n   CONTEXT_ORACLE = \\'context_oracle\\'\\n```\"}'\n",
      "  }\n",
      "\n",
      "\n",
      "Example 2\n",
      "=======\n",
      "\n",
      "*Note - In this more advanced case conversation is truncated in some parts*\n",
      "\n",
      "*User*\n",
      "  Return an answer in Markdown text which completely resolves the following issue:\n",
      "    \n",
      "    Github Issue Title  \n",
      "    Refactor DocEmbeddingHandler to better follow the Single Responsibility Principle\n",
      "\n",
      "    Github Issue Description\n",
      "    The current implementation of SymbolDocEmbeddingHandler performs multiple operations related to symbol documentation embedding. This makes the class harder to maintain, test, and reason about. To improve this, we need to refactor the class to better adhere to the Single Responsibility Principle.\n",
      "\n",
      "    Two major responsibilities stand out:\n",
      "\n",
      "    Embedding Management: This covers processing, updating, and building of symbol documentation embeddings.\n",
      "    Context Retrieval and Search: This involves retrieving Python contexts for symbols and generating search lists for symbols.\n",
      "    Proposed Changes\n",
      "\n",
      "    Embedding Management: Create a new class, EmbeddingManager, to handle operations like processing existing embeddings, building new ones, and updating existing ones.\n",
      "    Context Retrieval and Search: Create a new class, ContextAndSearchHandler, to manage the retrieval of Python contexts for symbols and the generation of relevant search lists.\n",
      "    By making these changes, the SymbolDocEmbeddingHandler class will become more focused and manageable, thereby adhering more closely to the Single Responsibility Principle. This task will involve careful refactoring and thorough testing to ensure all functionality remains intact after the changes.\n",
      "    \n",
      "\n",
      "*Assistant*\n",
      "  function_call:\n",
      "    {\n",
      "      'name': 'context_oracle', \n",
      "      'arguments': '{\"query\": \"SymbolDocEmbeddingHandler\"}'\n",
      "    }\n",
      "\n",
      "*User*\n",
      "  Execution Result:\n",
      "\n",
      "  class SymbolDocEmbeddingHandler(SymbolEmbeddingHandler):\n",
      "      \"\"\"\n",
      "      Handles a database and provider for `Symbol` documentation embeddings.\n",
      "      TODO: Add more robust logic for documentation updates.\n",
      "      \"\"\"\n",
      "\n",
      "      ...CODE CONTINUES...\n",
      "\n",
      "*Assistant*\n",
      "  function_call:\n",
      "    {\n",
      "      'name': 'context_oracle', \n",
      "      'arguments': '{\"query\": \"SymbolEmbeddingHandler\"}'\n",
      "    }\n",
      "\n",
      "*User*\n",
      "  Execution Result:\n",
      "\n",
      "  ...CODE CONTINUES...\n",
      "\n",
      "*Assistant*\n",
      "  content:\n",
      "    Let us first analyze the pros and cons of this implementation before directly returning a result.\n",
      "    Based on the current implementation of `SymbolDocEmbedding`, and its context, we can propose the following changes to make it more robust:\n",
      "    ...CODE CONTINUES...\n",
      "\n",
      "*User*\n",
      "  Continue...\n",
      "\n",
      "  NOTE - YOU HAVE EXCEEDED YOUR MAXIMUM ALLOWABLE ITERATIONS, RETURN A RESULT NOW WITH call_termination.\n",
      "\n",
      "*Assistant*\n",
      "  function_call:\n",
      "    {\n",
      "      'name': 'call_termination', \n",
      "      'arguments': '{\"result\": \"```python\\nclass  SymbolDocEmbeddingHandler(SymbolEmbeddingHandler): ...CODE CONTINUES...```\"}'\n",
      "    }\n",
      "\n",
      "Note, the examples above are meant to provide necessary context to show the nature of the system.  In production, the string '...CODE CONTINUES...' would be replaced with the actual code.  Your job then is to generate the code based on the given context.\n",
      "\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[36m\n",
      "------------------------------------------------------------\n",
      "Session ID: 0b1b2c38-be31-41b0-a38b-677478c61017\n",
      "------------------------------------------------------------\n",
      "\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import textwrap\n",
    "instructions = textwrap.dedent('''\n",
    "Provide a markdown python snippet, which can validly executed by `exec`. When ran, the snippet produces a valid instance of an openai agent config in the local variable `x`.\n",
    "''')\n",
    "agent = OpenAIAutomataAgent(instructions, config=agent_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4cad1214",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Latest Assistant Message -- \n",
      "\u001b[0m\n",
      "\u001b[36mApproximately 3041 tokens were consumed prior to completion generation.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mFunction\u001b[0m \u001b[32mCall:\n",
      "call_termination\n",
      "\n",
      "Arguments:\n",
      "{\n",
      "\u001b[0m \u001b[32m\u001b[0m \u001b[32m\"result\":\u001b[0m \u001b[32m\"```python\\nimport\u001b[0m \u001b[32mopenai\\n\\nclass\u001b[0m \u001b[32mOpenAIAgentConfig:\\n\u001b[0m \u001b[32m\u001b[0m \u001b[32m\u001b[0m \u001b[32m\u001b[0m \u001b[32mdef\u001b[0m \u001b[32m__init__(self):\\n\u001b[0m \u001b[32m\u001b[0m \u001b[32m\u001b[0m \u001b[32m\u001b[0m \u001b[32m\u001b[0m \u001b[32m\u001b[0m \u001b[32m\u001b[0m \u001b[32m\u001b[0m \u001b[32mself.model\u001b[0m \u001b[32m=\u001b[0m \u001b[32m\\\"gpt-3.5-turbo\\\"\\n\u001b[0m \u001b[32m\u001b[0m \u001b[32m\u001b[0m \u001b[32m\u001b[0m \u001b[32m\u001b[0m \u001b[32m\u001b[0m \u001b[32m\u001b[0m \u001b[32m\u001b[0m \u001b[32mself.max_tokens\u001b[0m \u001b[32m=\u001b[0m \u001b[32m100\\n\u001b[0m \u001b[32m\u001b[0m \u001b[32m\u001b[0m \u001b[32m\u001b[0m \u001b[32m\u001b[0m \u001b[32m\u001b[0m \u001b[32m\u001b[0m \u001b[32m\u001b[0m \u001b[32mself.temperature\u001b[0m \u001b[32m=\u001b[0m \u001b[32m0.8\\n\u001b[0m \u001b[32m\u001b[0m \u001b[32m\u001b[0m \u001b[32m\u001b[0m \u001b[32m\u001b[0m \u001b[32m\u001b[0m \u001b[32m\u001b[0m \u001b[32m\u001b[0m \u001b[32mself.stop_sequence\u001b[0m \u001b[32m=\u001b[0m \u001b[32m\\\"\\\\n\\\"\\n\u001b[0m \u001b[32m\u001b[0m \u001b[32m\u001b[0m \u001b[32m\u001b[0m \u001b[32m\u001b[0m \u001b[32m\u001b[0m \u001b[32m\u001b[0m \u001b[32m\u001b[0m \u001b[32mself.n\u001b[0m \u001b[32m=\u001b[0m \u001b[32m1\\n\u001b[0m \u001b[32m\u001b[0m \u001b[32m\u001b[0m \u001b[32m\u001b[0m \u001b[32m\u001b[0m \u001b[32m\u001b[0m \u001b[32m\u001b[0m \u001b[32m\u001b[0m \u001b[32mself.logprobs\u001b[0m \u001b[32m=\u001b[0m \u001b[32m0\\n\\nx\u001b[0m \u001b[32m=\u001b[0m \u001b[32mOpenAIAgentConfig()\\n```\"\n",
      "}\n",
      "\n",
      "\u001b[0m "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36mApproximately 3045 tokens were after adding the latest message.\u001b[0m\n",
      "\u001b[36m\n",
      "------------------------------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[36mLatest User Message -- \n",
      "OpenAIChatMessage(role=user, content=```python\n",
      "import openai\n",
      "\n",
      "class OpenAIAgentConfig:\n",
      "    def __init__(self):\n",
      "        self.model = \"gpt-3.5-turbo\"\n",
      "        self.max_tokens = 100\n",
      "        self.temperature = 0.8\n",
      "        self.stop_sequence = \"\\n\"\n",
      "        self.n = 1\n",
      "        self.logprobs = 0\n",
      "\n",
      "x = OpenAIAgentConfig()\n",
      "```, function_call=None)\n",
      "\u001b[0m\n",
      "\u001b[36mApproximately 3134 tokens were after adding the latest message.\u001b[0m\n",
      "\u001b[36m\n",
      "------------------------------------------------------------------------------------------------------------------------\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Run the agent\n",
    "result = agent.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8809bae0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result:\n",
      "```python\n",
      "import openai\n",
      "\n",
      "class OpenAIAgentConfig:\n",
      "    def __init__(self):\n",
      "        self.model = \"gpt-3.5-turbo\"\n",
      "        self.max_tokens = 100\n",
      "        self.temperature = 0.8\n",
      "        self.stop_sequence = \"\\n\"\n",
      "        self.n = 1\n",
      "        self.logprobs = 0\n",
      "\n",
      "x = OpenAIAgentConfig()\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "# Print the result\n",
    "print(f\"Result:\\n{result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "03e805b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# We need to first import PyReader\n",
      "from automata.code_parsers.py.py_reader import PyReader\n",
      "\n",
      "# Next we create an instance of PyReader and assign it to the variable x\n",
      "x = PyReader()\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result='```python\\nfrom automata.config.openai_agent import OpenAIAutomataAgentConfig\\n\\nx = OpenAIAutomataAgentConfig()\\nx.setup()```'\n",
    "result='```python\\n# We need to first import PyReader\\nfrom automata.code_parsers.py.py_reader import PyReader\\n\\n# Next we create an instance of PyReader and assign it to the variable x\\nx = PyReader()\\n```'\n",
    "cleaned_result = result.split('```python\\n')[1].replace('```','')\n",
    "print(cleaned_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "96300734-4095-4f29-a812-5f33b4ffa286",
   "metadata": {},
   "outputs": [],
   "source": [
    "exec(cleaned_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "003e4d4f-d11c-4048-810a-001028dd2bed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36mPopen(['git', 'version'], cwd=/Users/nolantremelling/automata/examples, universal_newlines=False, shell=None, istream=None)\u001b[0m\n",
      "\u001b[36mPopen(['git', 'version'], cwd=/Users/nolantremelling/automata/examples, universal_newlines=False, shell=None, istream=None)\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n# We need to first import PyReader\\nfrom automata.code_parsers.py.py_reader import PyReader\\n\\n# Next we create an instance of PyReader and assign it to the variable x\\nx = PyReader()\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from automata.eval import (\n",
    "    AgentEval,\n",
    "    AgentEvalSetLoader,\n",
    "    AgentEvaluationHarness,\n",
    "    CodeWritingEval,\n",
    "    OpenAIFunctionEval,\n",
    "    CodeWritingAction\n",
    ")\n",
    "CodeWritingAction._extract_snippet(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
